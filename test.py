# ==========================================
# ğŸ§ª ZIæŠœããƒ»èƒ½åŠ›ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ« æ¤œè¨¼ç”¨ã‚³ãƒ¼ãƒ‰
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import re
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_auc_score
from sklearn.preprocessing import LabelEncoder

# 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
# ------------------------------------------
file_path = 'race_data_5years.csv' # 5å¹´åˆ†ãƒ‡ãƒ¼ã‚¿

print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™... ({file_path})")
try:
    df = pd.read_csv(file_path, encoding='utf-8-sig', low_memory=False)
except:
    try:
        df = pd.read_csv(file_path, encoding='cp932', low_memory=False)
    except:
        df = pd.read_csv(file_path, encoding='shift_jis', errors='ignore', low_memory=False)

# 2. ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ------------------------------------------
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
df['ç€é †_num'] = df['ç€é †'].apply(force_numeric)
df = df.dropna(subset=['ç€é †_num'])
df['target'] = (df['ç€é †_num'] == 1).astype(int)

# åˆ—åã®æºã‚‰ãå¸å & æ•°å€¤åŒ–
cols_map = {
    'å‰èµ°ç€é †': 'å‰èµ°ç€é †_num',
    'ç€é †.1': 'å‰èµ°ç€é †_num',
    'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ': 'å‰èµ°ç€å·®',
    'ç€å·®.1': 'å‰èµ°ç€å·®',
    'å‰èµ°è£œæ­£': 'å‰èµ°è£œæ­£',
    'è£œæ­£ã‚¿ã‚¤ãƒ .1': 'å‰èµ°è£œæ­£',
    'å‰PCI': 'å‰èµ°PCI',
    'å‰èµ°PCI': 'å‰èµ°PCI',
    'å‰èµ°RPCI': 'å‰èµ°RPCI',
    'å‰èµ°Ave-3F': 'å‰èµ°Ave3F',
    'å‰èµ°ä¸Šã‚Š3F': 'å‰èµ°ä¸Šã‚Š3F'
}

# ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†
df_model = pd.DataFrame()
df_model['target'] = df['target']
df_model['Odds'] = df['å˜å‹ã‚ªãƒƒã‚º'].apply(force_numeric).fillna(0)

# ã‚³ãƒ¼ã‚¹IDä½œæˆ
if 'å ´æ‰€' not in df.columns and 'é–‹å‚¬' in df.columns:
    place_map = {'æœ­':'æœ­å¹Œ', 'å‡½':'å‡½é¤¨', 'ç¦':'ç¦å³¶', 'æ–°':'æ–°æ½Ÿ', 'æ±':'æ±äº¬', 'ä¸­':'ä¸­å±±', 'äº¬':'äº¬éƒ½', 'é˜ª':'é˜ªç¥', 'å°':'å°å€‰'}
    df['å ´æ‰€'] = df['é–‹å‚¬'].astype(str).apply(lambda x: place_map.get(x[1], 'ãã®ä»–') if len(x)>1 else 'ãã®ä»–')
if 'å ´æ‰€' not in df.columns: df['å ´æ‰€'] = 'ãã®ä»–'
if 'èŠãƒ»ãƒ€' not in df.columns: df['èŠãƒ»ãƒ€'] = 'èŠ'
if 'è·é›¢' not in df.columns: df['è·é›¢'] = 1600

df['ã‚³ãƒ¼ã‚¹ID'] = df['å ´æ‰€'].astype(str) + df['èŠãƒ»ãƒ€'].astype(str) + df['è·é›¢'].astype(str)
le = LabelEncoder()
df_model['ã‚³ãƒ¼ã‚¹ID'] = le.fit_transform(df['ã‚³ãƒ¼ã‚¹ID'].astype(str))

# ç‰¹å¾´é‡ã®å–ã‚Šè¾¼ã¿ (ZIã¯é™¤å¤–)
features = [
    'å‰èµ°è£œæ­£',       # ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°
    'å‰èµ°ç€é †_num',   # ç€é †
    'å‰èµ°ç€å·®',       # ã‚¿ã‚¤ãƒ å·®
    'å‰èµ°PCI',        # ãƒ©ãƒƒãƒ—ãƒãƒ©ãƒ³ã‚¹
    'å‰èµ°RPCI',       # ãƒ¬ãƒ¼ã‚¹ãƒšãƒ¼ã‚¹
    'å‰èµ°Ave3F',      # ã‚¹ãƒ”ãƒ¼ãƒ‰
    'å‰èµ°ä¸Šã‚Š3F',     # æœ«è„š
    'ã‚³ãƒ¼ã‚¹ID'        # é©æ€§
]

for f in features:
    # ãƒãƒƒãƒ”ãƒ³ã‚°å¯¾å¿œ
    found = False
    for k, v in cols_map.items():
        if v == f and k in df.columns:
            df_model[f] = df[k].apply(force_numeric)
            found = True
            break
    if not found and f in df.columns:
        df_model[f] = df[f].apply(force_numeric)
    
    # æ¬ æåŸ‹ã‚
    if f in df_model.columns:
        df_model[f] = df_model[f].fillna(df_model[f].mean())
    else:
        df_model[f] = 0 # ãªã‘ã‚Œã°0

# 3. å­¦ç¿’ & äºˆæ¸¬
# ------------------------------------------
X = df_model[features]
y = df_model['target']
odds = df_model['Odds']

X_train, X_test, y_train, y_test, odds_train, odds_test = train_test_split(
    X, y, odds, test_size=0.2, random_state=42
)

print("ğŸ”¥ ZIæŠœããƒ»ãƒ©ãƒƒãƒ—ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
model.fit(X_train, y_train)

# äºˆæ¸¬
probs = model.predict_proba(X_test)[:, 1]
auc = roc_auc_score(y_test, probs)
print(f"\nâœ… ãƒ¢ãƒ‡ãƒ«ç²¾åº¦(AUC): {auc:.4f}")

# é‡è¦åº¦
print("\n=== ğŸ“Š é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° (ZIãªã—) ===")
imp = pd.DataFrame({'feature': features, 'gain': model.booster_.feature_importance(importance_type='gain')})
print(imp.sort_values('gain', ascending=False))

# 4. ğŸ’° é»„é‡‘ã®è²·ã„æ–¹ ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
# ------------------------------------------
print("\n=== ğŸ’° å›åç‡100%è¶…ãˆæ¡ä»¶ã®æ¢ç´¢ ===")
sim_df = pd.DataFrame({'target': y_test, 'prob': probs, 'odds': odds_test})
sim_df['ev'] = sim_df['prob'] * sim_df['odds']

best_conds = []
# æ¡ä»¶ç·å½“ãŸã‚Š (å°‘ã—ç¯„å›²ã‚’åºƒã’ã¾ã™)
for min_odds in [5.0, 10.0, 15.0, 20.0, 30.0]:
    for max_odds in [50.0, 100.0, 150.0]:
        if min_odds >= max_odds: continue
        for min_ev in [0.8, 1.0, 1.2, 1.5, 2.0]:
            
            bets = sim_df[
                (sim_df['odds'] >= min_odds) & 
                (sim_df['odds'] < max_odds) & 
                (sim_df['ev'] >= min_ev)
            ]
            
            cnt = len(bets)
            if cnt < 30: continue # ã‚µãƒ³ãƒ—ãƒ«å°‘ãªã™ãã¯é™¤å¤–
            
            hits = len(bets[bets['target'] == 1])
            ret = bets[bets['target'] == 1]['odds'].sum()
            rate = ret / cnt * 100
            
            if rate > 100:
                best_conds.append({
                    'æ¡ä»¶': f"ã‚ªãƒƒã‚º{min_odds}-{max_odds}å€ & æœŸå¾…å€¤{min_ev}â†‘",
                    'ä»¶æ•°': cnt,
                    'çš„ä¸­ç‡': f"{hits/cnt*100:.1f}%",
                    'å›åç‡': f"{rate:.1f}%"
                })

if best_conds:
    res_df = pd.DataFrame(best_conds)
    print(res_df.sort_values('å›åç‡', ascending=False).head(10))
else:
    print("æ¡ä»¶ä»˜ãã§ã‚‚100%è¶…ãˆã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")