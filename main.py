# ==========================================
# ğŸ‡ ç«¶é¦¬AI æœ€çµ‚ç‰ˆ (å‹ç‡è¡¨ç¤º & éå»3èµ°Maxè©•ä¾¡)
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import re
from sklearn.preprocessing import LabelEncoder

# ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
train_file = 'race_data_5years.csv' 
entry_file = 'entry_table.csv'

print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ãƒ¢ãƒ‡ãƒ«ã‚’æ§‹ç¯‰ã—ã¾ã™...")

# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
try:
    df_train = pd.read_csv(train_file, encoding='utf-8-sig', low_memory=False)
except:
    try:
        df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
    except:
        df_train = pd.read_csv(train_file, encoding='shift_jis', errors='ignore', low_memory=False)

# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

# åˆ—åã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
df_train.columns = df_train.columns.str.strip()
df_train = df_train.loc[:, ~df_train.columns.duplicated()]

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆä½œæˆ
if 'ç€é †' not in df_train.columns:
    if 'ç¢ºå®šç€é †' in df_train.columns: df_train['ç€é †'] = df_train['ç¢ºå®šç€é †']

df_train['ç€é †_num'] = df_train['ç€é †'].apply(force_numeric)
df_train = df_train.dropna(subset=['ç€é †_num'])
df_train['target'] = (df_train['ç€é †_num'] == 1).astype(int)

# ç‰¹å¾´é‡ãƒãƒƒãƒ”ãƒ³ã‚° (å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¯ã€Œå‰èµ°ã€ã—ã‹ãªã„ãŸã‚ãã®ã¾ã¾)
cols_map = {
    'å‰èµ°PCI': ['å‰PCI', 'å‰èµ°PCI', 'PCI'],
    'å‰èµ°RPCI': ['å‰RPCI', 'å‰èµ°RPCI', 'RPCI'],
    'å‰èµ°Ave3F': ['å‰èµ°Ave-3F', 'Ave-3F', 'Ave-3F.1'],
    'å‰èµ°è£œæ­£': ['è£œæ­£ã‚¿ã‚¤ãƒ .1', 'å‰èµ°è£œ9', 'è£œæ­£9']
}
for target, sources in cols_map.items():
    if target not in df_train.columns:
        for s in sources:
            if s in df_train.columns:
                df_train[target] = df_train[s]
                break
    # ãã‚Œã§ã‚‚ãªã‘ã‚Œã°0åŸ‹ã‚
    if target not in df_train.columns: df_train[target] = 0

# ã‚³ãƒ¼ã‚¹ID
if 'å ´æ‰€' not in df_train.columns: df_train['å ´æ‰€'] = 'ãã®ä»–'
if 'èŠãƒ»ãƒ€' not in df_train.columns: df_train['èŠãƒ»ãƒ€'] = 'èŠ'
if 'è·é›¢' not in df_train.columns: df_train['è·é›¢'] = 1600
df_train['ã‚³ãƒ¼ã‚¹ID'] = df_train['å ´æ‰€'].astype(str) + df_train['èŠãƒ»ãƒ€'].astype(str) + df_train['è·é›¢'].astype(str)

# ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡
features = [
    'å‰èµ°è£œæ­£', 'å‰èµ°ç€é †', 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ',
    'å‰èµ°PCI', 'å‰èµ°RPCI', 'å‰èµ°Ave3F', 'å‰èµ°ä¸Šã‚Š3F',
    'ã‚³ãƒ¼ã‚¹ID'
]

# æ•°å€¤åŒ– & æ¬ æåŸ‹ã‚
for f in features:
    if f == 'ã‚³ãƒ¼ã‚¹ID': continue
    if f in df_train.columns:
        df_train[f] = df_train[f].apply(force_numeric).fillna(0)
    else:
        df_train[f] = 0

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
le = LabelEncoder()
df_train['ã‚³ãƒ¼ã‚¹ID'] = le.fit_transform(df_train['ã‚³ãƒ¼ã‚¹ID'].astype(str))

# å­¦ç¿’å®Ÿè¡Œ
print("ğŸ”¥ èƒ½åŠ›ç‰¹åŒ–ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
X = df_train[features]
y = df_train['target']
model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
model.fit(X, y)
print("âœ… å­¦ç¿’å®Œäº†ï¼")

# ------------------------------------------------
# 2. æœ€æ–°ã‚ªãƒƒã‚ºã§ã®äºˆæƒ³ (éå»3èµ°è©•ä¾¡æ©Ÿèƒ½ä»˜ã)
# ------------------------------------------------
print(f"ğŸš€ æœ€æ–°ã®å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")

try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

# åˆ—åã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
df_entry.columns = df_entry.columns.str.strip()
df_entry = df_entry.loc[:, ~df_entry.columns.duplicated()]
df_pred = df_entry.copy()

# â˜…ã“ã“ãŒæ–°æ©Ÿèƒ½ï¼šéå»3èµ°ã‹ã‚‰ã®ã€Œæœ€å¤§èƒ½åŠ›ã€æŠ½å‡º
# å‡ºé¦¬è¡¨ã«ã‚ã‚‹ 'è£œ:1'(1èµ°å‰), 'è£œ:2'(2èµ°å‰), 'è£œ:3'(3èµ°å‰) ã‚’ä½¿ã„ã¾ã™
# â€»åˆ—åãŒ 'è£œæ­£ã‚¿ã‚¤ãƒ .1' ãªã©ã®å ´åˆã‚‚ã‚ã‚‹ã®ã§å¯¾å¿œã—ã¾ã™
hosei_cols = ['è£œ:1', 'è£œ:2', 'è£œ:3'] # CSVã®åˆ—åã‚’ç¢ºèªã—ã¦èª¿æ•´
if 'è£œ:1' not in df_pred.columns:
    # 'è£œæ­£ã‚¿ã‚¤ãƒ 'ãªã©ã®åå‰ã§å…¥ã£ã¦ã„ã‚‹å ´åˆã®äºˆå‚™ãƒªã‚¹ãƒˆ
    hosei_cols = ['è£œæ­£ã‚¿ã‚¤ãƒ .1', 'è£œæ­£ã‚¿ã‚¤ãƒ .2', 'è£œæ­£ã‚¿ã‚¤ãƒ .3']

# éå»3èµ°ã®æœ€å¤§å€¤ã‚’è¨ˆç®—ã™ã‚‹é–¢æ•°
def get_max_hosei(row):
    values = []
    for col in hosei_cols:
        if col in row.index:
            val = force_numeric(row[col])
            if val > 0: # 0ã‚„æ¬ æã¯é™¤å¤–
                values.append(val)
    
    if not values: return 0 # ãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ
    return max(values) # æœ€å¤§å€¤ã‚’è¿”ã™

print("ğŸ“Š éå»3èµ°ã®è£œæ­£ã‚¿ã‚¤ãƒ ã‹ã‚‰æœ€å¤§ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç®—å‡ºã—ã¾ã™...")
# ã€Œå‰èµ°è£œæ­£ã€ã¨ã„ã†é …ç›®ã«ã€ã‚ãˆã¦ã€Œéå»3èµ°ã®æœ€å¤§å€¤ã€ã‚’å…¥ã‚Œã‚‹ã“ã¨ã§
# ã€Œã“ã®é¦¬ã®ãƒ™ã‚¹ãƒˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€ã‚’AIã«è©•ä¾¡ã•ã›ã¾ã™
df_pred['å‰èµ°è£œæ­£'] = df_pred.apply(get_max_hosei, axis=1)

# ãã®ä»–ã®ãƒãƒƒãƒ”ãƒ³ã‚°
rename_map = {
    'ç€é †.1': 'å‰èµ°ç€é †', 'ç€å·®.1': 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ',
    'ä¸Šã‚Š3F.1': 'å‰èµ°ä¸Šã‚Š3F', 
    'PCI.1': 'å‰èµ°PCI', 'PCI': 'å‰èµ°PCI',
    'Ave-3F.1': 'å‰èµ°Ave3F', 'å˜å‹': 'å˜å‹ã‚ªãƒƒã‚º'
}
for k, v in rename_map.items():
    if k in df_pred.columns and v not in df_pred.columns:
        df_pred[v] = df_pred[k]

# å‡ºé¦¬è¡¨ã®ç‰¹å¾´é‡ä½œæˆ
if 'å ´æ‰€' not in df_pred.columns:
    if 'é–‹å‚¬' in df_pred.columns:
        place_map = {'æœ­':'æœ­å¹Œ', 'å‡½':'å‡½é¤¨', 'ç¦':'ç¦å³¶', 'æ–°':'æ–°æ½Ÿ', 'æ±':'æ±äº¬', 'ä¸­':'ä¸­å±±', 'äº¬':'äº¬éƒ½', 'é˜ª':'é˜ªç¥', 'å°':'å°å€‰'}
        df_pred['å ´æ‰€'] = df_pred['é–‹å‚¬'].astype(str).apply(lambda x: place_map.get(x[1], 'ãã®ä»–') if len(x)>1 else 'ãã®ä»–')
    else: df_pred['å ´æ‰€'] = 'ãã®ä»–'
if 'èŠãƒ»ãƒ€' not in df_pred.columns: df_pred['èŠãƒ»ãƒ€'] = 'èŠ' 
if 'è·é›¢' not in df_pred.columns: df_pred['è·é›¢'] = 1600 

df_pred['ã‚³ãƒ¼ã‚¹ID'] = df_pred['å ´æ‰€'].astype(str) + df_pred['èŠãƒ»ãƒ€'].astype(str) + df_pred['è·é›¢'].astype(str)

# ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°é©ç”¨
df_pred['ã‚³ãƒ¼ã‚¹ID'] = df_pred['ã‚³ãƒ¼ã‚¹ID'].apply(lambda x: x if x in le.classes_ else le.classes_[0])
df_pred['ã‚³ãƒ¼ã‚¹ID'] = le.transform(df_pred['ã‚³ãƒ¼ã‚¹ID'])

# æ•°å€¤åŒ– & æ¬ æåŸ‹ã‚
for f in features:
    if f == 'ã‚³ãƒ¼ã‚¹ID': continue
    if f in df_pred.columns:
        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã§ã¯ãªãã€0åŸ‹ã‚ã®æ–¹ãŒã€Œãƒ‡ãƒ¼ã‚¿ãªã—ã€ã‚’è¡¨ç¾ã—ã‚„ã™ã„å ´åˆã‚‚
        df_pred[f] = df_pred[f].apply(force_numeric).fillna(0)
    else:
        df_pred[f] = 0

# äºˆæ¸¬å®Ÿè¡Œ
X_pred = df_pred[features]
probs = model.predict_proba(X_pred)[:, 1]
df_pred['AIå‹ç‡(%)'] = (probs * 100).round(1)

# æœŸå¾…å€¤è¨ˆç®—
if 'å˜å‹ã‚ªãƒƒã‚º' in df_pred.columns:
    df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred['å˜å‹ã‚ªãƒƒã‚º'].apply(force_numeric).fillna(0)
    df_pred['æœŸå¾…å€¤'] = (df_pred['AIå‹ç‡(%)'] / 100) * df_pred['å˜å‹ã‚ªãƒƒã‚º']
else:
    df_pred['å˜å‹ã‚ªãƒƒã‚º'] = 0
    df_pred['æœŸå¾…å€¤'] = 0

# é¦¬åã®å–å¾—
name_col = 'é¦¬å'
if 'é¦¬å' not in df_pred.columns:
    cands = [c for c in df_pred.columns if 'é¦¬å' in c]
    if cands: name_col = cands[0]

# --- çµæœè¡¨ç¤º ---
cols = ['æ ç•ª', 'é¦¬ç•ª', name_col, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'å‰èµ°è£œæ­£']
disp_cols = [c for c in cols if c in df_pred.columns]

# 1. æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°
print("\n=== ğŸ¯ æ¨å¥¨é¦¬ãƒªã‚¹ãƒˆ (æœŸå¾…å€¤é †) ===")
print("â€»ã€å‰èµ°è£œæ­£ã€æ¬„ã¯ã€éå»3èµ°ã®ãƒ™ã‚¹ãƒˆæ•°å€¤ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™")
final_list_ev = df_pred[df_pred['å˜å‹ã‚ªãƒƒã‚º'] >= 1.0].sort_values('æœŸå¾…å€¤', ascending=False)
print(final_list_ev[disp_cols].head(10))

# 2. å‹ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (NEW!)
print("\n=== ğŸ† æ¨å¥¨é¦¬ãƒªã‚¹ãƒˆ (å‹ç‡é †) ===")
print("â€»ç´”ç²‹ãªå¼·ã•ã®è©•ä¾¡é †ã§ã™")
final_list_prob = df_pred.sort_values('AIå‹ç‡(%)', ascending=False)
print(final_list_prob[disp_cols].head(10))

if len(final_list_ev) > 0:
    top_ev = final_list_ev.iloc[0]
    print(f"\nğŸ’° æœŸå¾…å€¤No.1: {top_ev[name_col]} (æœŸå¾…å€¤ {top_ev['æœŸå¾…å€¤']:.2f})")
if len(final_list_prob) > 0:
    top_prob = final_list_prob.iloc[0]
    print(f"ğŸ‘‘ å‹ç‡No.1  : {top_prob[name_col]} (å‹ç‡ {top_prob['AIå‹ç‡(%)']}%)")