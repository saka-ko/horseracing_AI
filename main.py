# ==========================================
# ğŸ‡ ç«¶é¦¬AI (ZI & æ–­å±¤ç†è«–) - æ±ºå®šç‰ˆ
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import sys
import os
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import GroupShuffleSplit

# ------------------------------------------------
# 0. è¨­å®š
# ------------------------------------------------
train_file = 'race_5years_zi_hoseitime_kai.csv' 
entry_file = 'entry_table.csv'      

if len(sys.argv) > 1 and sys.argv[1].endswith('.csv'):
    entry_file = sys.argv[1]

# ------------------------------------------------
# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
# ------------------------------------------------
print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

try:
    df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
except:
    df_train = pd.read_csv(train_file, encoding='utf-8', low_memory=False)

df_train.columns = df_train.columns.str.strip()

# --- åˆ—åãƒãƒƒãƒ”ãƒ³ã‚° ---
col_map = {}
aliases = {
    'ç€é †': ['ç¢ºå®šç€é †', 'ç€é †'],
    'ZI': ['æŒ‡æ•°', 'ZI', 'ZIå€¤'],
    'ã‚ªãƒƒã‚º': ['å˜å‹ã‚ªãƒƒã‚º', 'å˜å‹', 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'],
    'ãƒ¬ãƒ¼ã‚¹ID': ['ãƒ¬ãƒ¼ã‚¹ID(æ–°)', 'ãƒ¬ãƒ¼ã‚¹ID(æ—§)', 'ãƒ¬ãƒ¼ã‚¹ID'],
    'å‰èµ°è£œæ­£': ['å‰èµ°è£œ9', 'å‰èµ°è£œæ­£', 'å‰èµ°ã‚¿ã‚¤ãƒ '] 
}

for key, candidates in aliases.items():
    for cand in candidates:
        if cand in df_train.columns:
            col_map[key] = cand
            break

if 'ç€é †' not in col_map or 'ZI' not in col_map:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã®åˆ—å: {list(df_train.columns)}")
    sys.exit(1)

# æ•°å€¤åŒ–é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        import re
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

# ãƒ‡ãƒ¼ã‚¿æ•´å½¢
df_train['target'] = (df_train[col_map['ç€é †']].apply(force_numeric) == 1).astype(int)
df_train['æŒ‡æ•°'] = df_train[col_map['ZI']].apply(force_numeric).fillna(0)
df_train['å˜å‹ã‚ªãƒƒã‚º'] = df_train[col_map['ã‚ªãƒƒã‚º']].apply(force_numeric).fillna(0)

if 'å‰èµ°è£œæ­£' in col_map:
    df_train['å‰èµ°è£œæ­£'] = df_train[col_map['å‰èµ°è£œæ­£']].apply(force_numeric).fillna(0)
else:
    df_train['å‰èµ°è£œæ­£'] = 0

# ãƒ¬ãƒ¼ã‚¹IDä¿®æ­£ï¼ˆé¦¬ç•ªã‚«ãƒƒãƒˆï¼‰
rid_col = col_map['ãƒ¬ãƒ¼ã‚¹ID']
df_train['rid_str'] = df_train[rid_col].astype(str)
if len(df_train) / df_train['rid_str'].nunique() < 5.0:
    df_train['rid_group'] = df_train['rid_str'].str[:-2]
else:
    df_train['rid_group'] = df_train['rid_str']

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
df_train['æŒ‡æ•°é †ä½'] = df_train.groupby('rid_group')['æŒ‡æ•°'].rank(ascending=False, method='min')
df_train['è£œæ­£é †ä½'] = df_train.groupby('rid_group')['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

features = ['æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'æŒ‡æ•°é †ä½', 'è£œæ­£é †ä½']
X = df_train[features]
y = df_train['target']

# ------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ï¼ˆæ­£ã—ã„åˆ†å‰²æ–¹æ³•ï¼‰
# ------------------------------------------------
print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ä¸­ï¼ˆãƒ¬ãƒ¼ã‚¹å˜ä½ã§æ­£ã—ãåˆ†å‰²ï¼‰...")

# â˜…é‡è¦: ãƒ¬ãƒ¼ã‚¹IDå˜ä½ã§åˆ†å‰²ã™ã‚‹ï¼ˆãƒãƒ©ãƒãƒ©æ®ºäººã‚’é˜²ãï¼‰
gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
train_idx, val_idx = next(gss.split(X, y, groups=df_train['rid_group']))

X_train = X.iloc[train_idx]
y_train = y.iloc[train_idx]
X_val = X.iloc[val_idx]
y_val = y.iloc[val_idx]

# æ¤œè¨¼ç”¨DF
df_val_sim = df_train.iloc[val_idx].copy()

# å­¦ç¿’
model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated_model.fit(X_train, y_train)

# äºˆæ¸¬
probs = calibrated_model.predict_proba(X_val)[:, 1]
df_val_sim['prob'] = probs
df_val_sim['expected_value'] = df_val_sim['prob'] * df_val_sim['å˜å‹ã‚ªãƒƒã‚º']

# --- ğŸ¦ ã‚ªãƒƒã‚ºæ–­å±¤ã®è¨ˆç®— ---
df_val_sim = df_val_sim.sort_values(by=['rid_group', 'å˜å‹ã‚ªãƒƒã‚º'])
df_val_sim['next_odds'] = df_val_sim.groupby('rid_group')['å˜å‹ã‚ªãƒƒã‚º'].shift(-1)
df_val_sim['gap_next'] = df_val_sim['next_odds'] / df_val_sim['å˜å‹ã‚ªãƒƒã‚º']
df_val_sim['gap_next'] = df_val_sim['gap_next'].fillna(1.0)

# === ğŸ§ª ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¡ä»¶ ===
# 1. ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: ZIæŒ‡æ•°1ä½ã‚’è²·ã„ç¶šã‘ã‚‹
cond_zi = df_val_sim['æŒ‡æ•°é †ä½'] == 1

# 2. AIæœ¬å‘½: AIã®ç¢ºç‡ãŒæœ€ã‚‚é«˜ã„é¦¬ã‚’è²·ã† (ã“ã‚ŒãŒçœŸã®å®ŸåŠ›)
# å„ãƒ¬ãƒ¼ã‚¹ã§probãŒæœ€å¤§ã®è¡Œã«ãƒ•ãƒ©ã‚°ã‚’ç«‹ã¦ã‚‹
idx_max_prob = df_val_sim.groupby('rid_group')['prob'].idxmax()
cond_ai_top = df_val_sim.index.isin(idx_max_prob)

# 3. AIæœŸå¾…å€¤ + ç¢ºç‡ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ (å¤§ç©´äº‹æ•…é˜²æ­¢)
# æœŸå¾…å€¤100å††ä»¥ä¸Šã€ã‹ã¤å‹ç‡ãŒ10%ä»¥ä¸Šã‚ã‚‹ç¾å®Ÿçš„ãªé¦¬
cond_ai_ev = (df_val_sim['expected_value'] >= 1.0) & (df_val_sim['prob'] >= 0.10)

# 4. æ–­å±¤ç†è«– (å‹ç‡10%ä»¥ä¸Š + æœŸå¾…å€¤100å†† + å¾Œã‚ã«æ–­å±¤)
cond_gap = (df_val_sim['expected_value'] >= 1.0) & \
           (df_val_sim['prob'] >= 0.10) & \
           (df_val_sim['gap_next'] >= 1.5)

def report_sim(name, condition):
    picks = df_val_sim[condition]
    if len(picks) == 0:
        print(f"  [{name}] è©²å½“ãªã—")
        return
    hits = picks[picks['target'] == 1]
    accuracy = len(hits) / len(picks) * 100
    return_rate = hits['å˜å‹ã‚ªãƒƒã‚º'].sum() / len(picks) * 100
    avg_odds = picks['å˜å‹ã‚ªãƒƒã‚º'].mean()
    print(f"  [{name}]")
    print(f"    è³¼å…¥: {len(picks)}R / å¹³å‡ã‚ªãƒƒã‚º: {avg_odds:.1f}å€")
    print(f"    ğŸ¯ çš„ä¸­ç‡: {accuracy:.2f}%")
    print(f"    ğŸ’° å›åç‡: {return_rate:.2f}%")

print(f"--- ğŸ æ¤œè¨¼çµæœ (ãƒ†ã‚¹ãƒˆæœŸé–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³) ---")
report_sim("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: ZIé †ä½1ä½ãƒ™ã‚¿è²·ã„", cond_zi)
print("-" * 40)
report_sim("ãƒ—ãƒ©ãƒ³A: AIè‡ªä¿¡åº¦No.1 (æœ¬å‘½ãƒ»å¯¾æŠ—)", cond_ai_top)
report_sim("ãƒ—ãƒ©ãƒ³B: AIæœŸå¾…å€¤ç‹™ã„ (å‹ç‡10%ä»¥ä¸Šé™å®š)", cond_ai_ev)
print("-" * 40)
report_sim("ãƒ—ãƒ©ãƒ³C: AI + ã‚ªãƒƒã‚ºæ–­å±¤ (å‹è² ãƒ¬ãƒ¼ã‚¹)", cond_gap)
print(f"--------------------------------------------------")

# æœ¬ç•ªå†å­¦ç¿’
print("ğŸ”„ æœ¬ç•ªç”¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ã¦ã„ã¾ã™...")
calibrated_model.fit(X, y)
print("âœ… å­¦ç¿’å®Œäº†ï¼")

# ------------------------------------------------
# 3. æœ€æ–°ã‚ªãƒƒã‚ºã§ã®äºˆæƒ³ (æ–­å±¤è¨ºæ–­æ©Ÿèƒ½ä»˜ã)
# ------------------------------------------------
print(f"\nğŸš€ å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")
# (ä»¥ä¸‹ã€äºˆæƒ³ãƒ‘ãƒ¼ãƒˆã¯å¤‰æ›´ãªã—ã®ãŸã‚ãã®ã¾ã¾ä½¿ãˆã¾ã™)
if not os.path.exists(entry_file):
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: äºˆæƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«({entry_file})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

df_entry.columns = df_entry.columns.str.strip()
df_pred = df_entry.copy()

# éå»3èµ°ã‹ã‚‰æœ€å¤§è£œæ­£ã‚¿ã‚¤ãƒ ã‚’å–å¾—
hosei_cols = []
for i in range(1, 4):
    c1 = f'è£œ:{i}'; c2 = f'è£œæ­£ã‚¿ã‚¤ãƒ .{i}'
    if c1 in df_pred.columns: hosei_cols.append(c1)
    elif c2 in df_pred.columns: hosei_cols.append(c2)
if 'è£œæ­£ã‚¿ã‚¤ãƒ ' in df_pred.columns: hosei_cols.append('è£œæ­£ã‚¿ã‚¤ãƒ ')

def get_max_hosei(row):
    vals = []
    for c in hosei_cols:
        v = force_numeric(row[c])
        if v > 0: vals.append(v)
    return max(vals) if vals else 0

df_pred['å‰èµ°è£œæ­£'] = df_pred.apply(get_max_hosei, axis=1)

if 'ZI' in df_pred.columns: df_pred['æŒ‡æ•°'] = df_pred['ZI'].apply(force_numeric).fillna(0)
else: df_pred['æŒ‡æ•°'] = 0

odds_col_entry = None
for c in ['å˜å‹', 'å˜å‹ã‚ªãƒƒã‚º', 'äºˆæƒ³å˜å‹ã‚ªãƒƒã‚º']:
    if c in df_pred.columns: odds_col_entry = c; break
df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred[odds_col_entry].apply(force_numeric).fillna(0) if odds_col_entry else 0

race_key = 'ãƒ¬ãƒ¼ã‚¹å' if 'ãƒ¬ãƒ¼ã‚¹å' in df_pred.columns else 'dummy'
if race_key == 'dummy': df_pred['dummy'] = 1

df_pred['æŒ‡æ•°é †ä½'] = df_pred.groupby(race_key)['æŒ‡æ•°'].rank(ascending=False, method='min')
df_pred['è£œæ­£é †ä½'] = df_pred.groupby(race_key)['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

X_pred = df_pred[features]
raw_probs = calibrated_model.predict_proba(X_pred)[:, 1]

total_prob = raw_probs.sum()
normalized_probs = raw_probs / total_prob if total_prob > 0 else raw_probs

df_pred['AIå‹ç‡(%)'] = (normalized_probs * 100).round(2)
df_pred['æœŸå¾…å€¤'] = (normalized_probs * df_pred['å˜å‹ã‚ªãƒƒã‚º'])

# é¦¬åå–å¾—
name_col = 'é¦¬å' if 'é¦¬å' in df_pred.columns else df_pred.columns[0]

# è¨ºæ–­ã‚³ãƒ¡ãƒ³ãƒˆ
def make_comment(row):
    res = []
    if row['æŒ‡æ•°é †ä½'] == 1: res.append("æŒ‡æ•°1ä½")
    if row['è£œæ­£é †ä½'] == 1: res.append("èƒ½åŠ›1ä½")
    if row['æœŸå¾…å€¤'] >= 1.0: res.append("â˜…æ¨å¥¨")
    return ",".join(res) if res else "-"
df_pred['è¨ºæ–­'] = df_pred.apply(make_comment, axis=1)

# ã‚ªãƒƒã‚ºæ–­å±¤åˆ†æ
def analyze_odds_gap(df_race):
    df_sorted = df_race[df_race['å˜å‹ã‚ªãƒƒã‚º'] > 0].sort_values('å˜å‹ã‚ªãƒƒã‚º')
    if len(df_sorted) < 6: return "âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³", []

    odds = df_sorted['å˜å‹ã‚ªãƒƒã‚º'].values
    gaps = odds[1:] / odds[:-1]
    
    diagnosis = []
    target_horse_indices = [] 

    if gaps[0] >= 2.5: diagnosis.append(f"ğŸ¦ 1ç•ªäººæ°—é‰„æ¿(æ–­å±¤{gaps[0]:.1f})")
    elif gaps[0] < 1.5: diagnosis.append(f"âš ï¸ 1ç•ªäººæ°—å±é™º(æ–­å±¤{gaps[0]:.1f})")

    middle_gaps = gaps[1:5] 
    if len(middle_gaps) > 0:
        max_gap_idx = np.argmax(middle_gaps) + 1 
        max_gap_val = middle_gaps[np.argmax(middle_gaps)]
        if max_gap_val >= 2.0:
            target_pop = max_gap_idx + 1
            target_name = df_sorted.iloc[max_gap_idx][name_col]
            diagnosis.append(f"ğŸ’° {target_pop}ç•ªäººæ°—({target_name})ç‹™ã„ç›®(å¾Œç¶šã¨æ–­å±¤{max_gap_val:.1f})")
            target_horse_indices.append(max_gap_idx)
    
    if all(g < 1.5 for g in gaps[:5]):
        diagnosis.append("ğŸ’¤ æ··æˆ¦ã‚¹ãƒ«ãƒ¼æ¨å¥¨")

    return " / ".join(diagnosis), df_sorted.iloc[target_horse_indices][name_col].tolist()

cols_out = ['æ ç•ª', 'é¦¬ç•ª', name_col, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'è¨ºæ–­', 'æŒ‡æ•°', 'å‰èµ°è£œæ­£']
disp_cols = [c for c in cols_out if c in df_pred.columns]

print("\n=== ğŸ“Š ã‚ªãƒƒã‚ºæ–­å±¤åˆ†æ (ãƒãƒ¼ã‚±ãƒƒãƒˆå¿ƒç†) ===")
gap_msg, gap_targets = analyze_odds_gap(df_pred)
print(f"ğŸ’¬ {gap_msg}")
if gap_targets:
    print(f"ğŸ‘‰ æ–­å±¤ç†è«–ã®æ³¨ç›®é¦¬: {', '.join(gap_targets)}")

print("\n=== ğŸ’° æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===")
print(df_pred[df_pred['å˜å‹ã‚ªãƒƒã‚º'] >= 1.0].sort_values('æœŸå¾…å€¤', ascending=False)[disp_cols].head(15))