# ==========================================
# ğŸ‡ ç«¶é¦¬AI (ZI & è£œæ­£ã‚¿ã‚¤ãƒ ç‰¹åŒ–å‹) - å®Œå…¨ç‰ˆ
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import sys
import os
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split

# ------------------------------------------------
# 0. è¨­å®š
# ------------------------------------------------
train_file = 'race_5years_zi_hoseitime_kai.csv' # ã„ãŸã ã„ãŸãƒ•ã‚¡ã‚¤ãƒ«
entry_file = 'entry_table.csv'      # äºˆæƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°å¯¾å¿œ
if len(sys.argv) > 1 and sys.argv[1].endswith('.csv'):
    entry_file = sys.argv[1]

# ------------------------------------------------
# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆæ”¹è‰¯ç‰ˆï¼‰
# ------------------------------------------------
print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

try:
    df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
except:
    df_train = pd.read_csv(train_file, encoding='utf-8', low_memory=False)

df_train.columns = df_train.columns.str.strip()

# --- â˜…åˆ—åã®è‡ªå‹•ãƒãƒƒãƒ”ãƒ³ã‚° ---
col_map = {}
# å¿…é ˆåˆ—ã®ã‚¨ã‚¤ãƒªã‚¢ã‚¹ï¼ˆåˆ¥åï¼‰å®šç¾©
aliases = {
    'ç€é †': ['ç¢ºå®šç€é †', 'ç€é †'],
    'ZI': ['æŒ‡æ•°', 'ZI', 'ZIå€¤'],
    'ã‚ªãƒƒã‚º': ['å˜å‹ã‚ªãƒƒã‚º', 'å˜å‹', 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'],
    'ãƒ¬ãƒ¼ã‚¹ID': ['ãƒ¬ãƒ¼ã‚¹ID(æ–°)', 'ãƒ¬ãƒ¼ã‚¹ID(æ—§)', 'ãƒ¬ãƒ¼ã‚¹ID'],
    # é‡è¦: ã“ã“ã§ã€Œå‰èµ°ã€ã®ãƒ‡ãƒ¼ã‚¿ã ã‘ã‚’é¸ã¶
    'å‰èµ°è£œæ­£': ['å‰èµ°è£œ9', 'å‰èµ°è£œæ­£', 'å‰èµ°ã‚¿ã‚¤ãƒ '] 
}

for key, candidates in aliases.items():
    for cand in candidates:
        if cand in df_train.columns:
            col_map[key] = cand
            break

# å¿…é ˆãƒã‚§ãƒƒã‚¯
if 'ç€é †' not in col_map or 'ZI' not in col_map:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã®åˆ—å: {list(df_train.columns)}")
    sys.exit(1)

print("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’æ­£ã—ãèªè­˜ã—ã¾ã—ãŸï¼")

# æ•°å€¤åŒ–é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        import re
        # å…¨è§’â†’åŠè§’, æ•°å­—ä»¥å¤–å‰Šé™¤
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

# ãƒ‡ãƒ¼ã‚¿æ•´å½¢
df_train['target'] = (df_train[col_map['ç€é †']].apply(force_numeric) == 1).astype(int)
df_train['æŒ‡æ•°'] = df_train[col_map['ZI']].apply(force_numeric).fillna(0)
df_train['å˜å‹ã‚ªãƒƒã‚º'] = df_train[col_map['ã‚ªãƒƒã‚º']].apply(force_numeric).fillna(0)

# è£œæ­£ã‚¿ã‚¤ãƒ ï¼ˆå‰èµ°ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨ï¼‰
if 'å‰èµ°è£œæ­£' in col_map:
    df_train['å‰èµ°è£œæ­£'] = df_train[col_map['å‰èµ°è£œæ­£']].apply(force_numeric).fillna(0)
else:
    # ãªã‘ã‚Œã°0ã§åŸ‹ã‚ã‚‹ï¼ˆã‚¨ãƒ©ãƒ¼ã«ã—ãªã„ï¼‰
    df_train['å‰èµ°è£œæ­£'] = 0

# --- ğŸš¨ ãƒ¬ãƒ¼ã‚¹IDã®ä¿®æ­£ï¼ˆ18æ¡å•é¡Œå¯¾ç­–ï¼‰ ---
# ãƒ¬ãƒ¼ã‚¹IDãŒé•·ã™ãã‚‹ï¼ˆé¦¬ç•ªè¾¼ã¿ï¼‰å ´åˆã¯ã€æœ«å°¾2æ¡ã‚’ã‚«ãƒƒãƒˆã—ã¦ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ã™ã‚‹
rid_col = col_map['ãƒ¬ãƒ¼ã‚¹ID']
df_train['rid_str'] = df_train[rid_col].astype(str)
# ç°¡æ˜“åˆ¤å®š: å¹³å‡é ­æ•°ãŒ5é ­ä»¥ä¸‹ãªã‚‰IDãŒç´°ã‹ã™ãã‚‹ã¨åˆ¤æ–­
if len(df_train) / df_train['rid_str'].nunique() < 5.0:
    print("â„¹ï¸ ãƒ¬ãƒ¼ã‚¹IDã‚’è£œæ­£ã—ã¾ã™ï¼ˆé¦¬ç•ªã‚’é™¤å»ã—ã¦ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰")
    df_train['rid_group'] = df_train['rid_str'].str[:-2]
else:
    df_train['rid_group'] = df_train['rid_str']

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
df_train['æŒ‡æ•°é †ä½'] = df_train.groupby('rid_group')['æŒ‡æ•°'].rank(ascending=False, method='min')
df_train['è£œæ­£é †ä½'] = df_train.groupby('rid_group')['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

features = ['æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'æŒ‡æ•°é †ä½', 'è£œæ­£é †ä½']
X = df_train[features]
y = df_train['target']

# ------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ & å­¦ç¿’
# ------------------------------------------------
print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«ã®å®ŸåŠ›ã‚’æ¤œè¨¼ä¸­ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚’8:2ã«åˆ†å‰²ï¼‰...")

# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
val_indices = X_val.index
val_odds = df_train.loc[val_indices, 'å˜å‹ã‚ªãƒƒã‚º']
val_rids = df_train.loc[val_indices, 'rid_group']

# å­¦ç¿’
model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
calibrated = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated.fit(X_train, y_train)

# æ¤œè¨¼ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
probs_val = calibrated.predict_proba(X_val)[:, 1]
df_sim = pd.DataFrame({'rid': val_rids, 'target': y_val, 'prob': probs_val, 'odds': val_odds})

# å„ãƒ¬ãƒ¼ã‚¹ã§ã€ŒAIæ¨å¥¨1ä½ã€ã®é¦¬ã®ã¿è³¼å…¥
bets = df_sim.sort_values('prob', ascending=False).groupby('rid').head(1)
hits = bets[bets['target'] == 1]

accuracy = (len(hits) / len(bets)) * 100
recovery = (hits['odds'].sum() / len(bets)) * 100

print(f"--- ğŸ æ¤œè¨¼çµæœ (ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ {len(bets)}ãƒ¬ãƒ¼ã‚¹) ---")
print(f"ğŸ¯ çš„ä¸­ç‡: {accuracy:.2f}%")
print(f"ğŸ’° å›åç‡: {recovery:.2f}%")
print(f"--------------------------------------------------")

# æœ¬ç•ªç”¨å†å­¦ç¿’
print("ğŸ”„ æœ¬ç•ªç”¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ã¦ã„ã¾ã™...")
calibrated.fit(X, y)
print("âœ… å­¦ç¿’å®Œäº†ï¼æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆäºˆæƒ³ï¼‰ã¸é€²ã‚ã¾ã™ã€‚")


# ------------------------------------------------
# 2. æœ€æ–°ã‚ªãƒƒã‚ºã§ã®äºˆæƒ³ (éå»3èµ°è©•ä¾¡)
# ------------------------------------------------
print(f"ğŸš€ å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")

if not os.path.exists(entry_file):
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: äºˆæƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«({entry_file})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

# åˆ—åã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
df_entry.columns = df_entry.columns.str.strip()
df_entry = df_entry.loc[:, ~df_entry.columns.duplicated()]
df_pred = df_entry.copy()

# --- â˜…é‡è¦: éå»3èµ°ã‹ã‚‰æœ€å¤§è£œæ­£ã‚¿ã‚¤ãƒ ã‚’å–å¾— ---
# åˆ—åã‚’æ¢ã™ (è£œ:1, è£œ:2, è£œ:3 ã¾ãŸã¯ è£œæ­£ã‚¿ã‚¤ãƒ .1, è£œæ­£ã‚¿ã‚¤ãƒ .2...)
hosei_cols = []
for i in range(1, 4):
    c1 = f'è£œ:{i}'
    c2 = f'è£œæ­£ã‚¿ã‚¤ãƒ .{i}'
    if c1 in df_pred.columns: hosei_cols.append(c1)
    elif c2 in df_pred.columns: hosei_cols.append(c2)

# ã€Œè£œæ­£ã‚¿ã‚¤ãƒ ã€è‡ªä½“ã‚‚å€™è£œã«å…¥ã‚Œã‚‹ï¼ˆTARGETã®ä»•æ§˜ã«ã‚ˆã‚Š1èµ°å‰ã®å ´åˆãŒã‚ã‚‹ï¼‰
if 'è£œæ­£ã‚¿ã‚¤ãƒ ' in df_pred.columns:
    hosei_cols.append('è£œæ­£ã‚¿ã‚¤ãƒ ')

# é‡è¤‡é™¤å»
hosei_cols = list(set(hosei_cols))
# print(f"â„¹ï¸ å‚ç…§ã™ã‚‹éå»èµ°ãƒ‡ãƒ¼ã‚¿åˆ—: {hosei_cols}")

def get_max_hosei(row):
    vals = []
    for c in hosei_cols:
        v = force_numeric(row[c])
        if v > 0: vals.append(v)
    return max(vals) if vals else 0

# æœ€å¤§å€¤ã‚’ã€Œå‰èµ°è£œæ­£ã€ã¨ã—ã¦æ‰±ã†
df_pred['å‰èµ°è£œæ­£'] = df_pred.apply(get_max_hosei, axis=1)

# æŒ‡æ•° (ZI)
if 'ZI' in df_pred.columns: df_pred['æŒ‡æ•°'] = df_pred['ZI'].apply(force_numeric).fillna(0)
else: df_pred['æŒ‡æ•°'] = 0

# å˜å‹ã‚ªãƒƒã‚º
odds_col = None
for c in ['å˜å‹', 'å˜å‹ã‚ªãƒƒã‚º', 'äºˆæƒ³å˜å‹ã‚ªãƒƒã‚º']:
    if c in df_pred.columns:
        odds_col = c
        break
if odds_col:
    df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred[odds_col].apply(force_numeric).fillna(0)
else:
    df_pred['å˜å‹ã‚ªãƒƒã‚º'] = 0

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
# ãƒ¬ãƒ¼ã‚¹åãŒãªã„å ´åˆã€ã™ã¹ã¦åŒã˜ãƒ¬ãƒ¼ã‚¹ã¨ã¿ãªã—ã¦é †ä½ã‚’ã¤ã‘ã‚‹
race_key = 'ãƒ¬ãƒ¼ã‚¹å' 
if race_key not in df_pred.columns:
    df_pred['dummy'] = 1
    race_key = 'dummy'

df_pred['æŒ‡æ•°é †ä½'] = df_pred.groupby(race_key)['æŒ‡æ•°'].rank(ascending=False, method='min')
df_pred['è£œæ­£é †ä½'] = df_pred.groupby(race_key)['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

# äºˆæ¸¬å®Ÿè¡Œ
X_pred = df_pred[features]
raw_probs = calibrated_model.predict_proba(X_pred)[:, 1]

# â˜…ç¢ºç‡ã®æ­£è¦åŒ–ï¼ˆåˆè¨ˆã‚’100%ã«ã™ã‚‹ï¼‰
total_prob = raw_probs.sum()
if total_prob > 0:
    normalized_probs = raw_probs / total_prob
else:
    normalized_probs = raw_probs

df_pred['AIå‹ç‡(%)'] = (normalized_probs * 100).round(2)
df_pred['æœŸå¾…å€¤'] = (normalized_probs * df_pred['å˜å‹ã‚ªãƒƒã‚º'])

# é¦¬åå–å¾—
name_col = 'é¦¬å'
if 'é¦¬å' not in df_pred.columns:
    cands = [c for c in df_pred.columns if 'é¦¬å' in c]
    if cands: name_col = cands[0]

# è¨ºæ–­ã‚³ãƒ¡ãƒ³ãƒˆ
def make_comment(row):
    res = []
    if row['æŒ‡æ•°é †ä½'] == 1: res.append("æŒ‡æ•°1ä½")
    if row['è£œæ­£é †ä½'] == 1: res.append("èƒ½åŠ›1ä½")
    elif row['è£œæ­£é †ä½'] <= 3: res.append("èƒ½åŠ›ä¸Šä½")
    if row['æœŸå¾…å€¤'] >= 1.0: res.append("â˜…æ¨å¥¨")
    return ",".join(res) if res else "-"

df_pred['è¨ºæ–­'] = df_pred.apply(make_comment, axis=1)

# --- çµæœå‡ºåŠ› ---
cols_out = ['æ ç•ª', 'é¦¬ç•ª', name_col, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'è¨ºæ–­', 'æŒ‡æ•°', 'å‰èµ°è£œæ­£']
disp_cols = [c for c in cols_out if c in df_pred.columns]

# 1. æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°
print("\n=== ğŸ’° æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚° (å›åç‡é‡è¦–) ===")
print("â€»ã€å‰èµ°è£œæ­£ã€æ¬„ã¯ã€éå»3èµ°ã®ãƒ™ã‚¹ãƒˆæ•°å€¤ã‚’è¡¨ç¤ºã—ã¦ã„ã¾ã™")
final_list_ev = df_pred[df_pred['å˜å‹ã‚ªãƒƒã‚º'] >= 1.0].sort_values('æœŸå¾…å€¤', ascending=False)
print(final_list_ev[disp_cols].head(15))

# 2. å‹ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚°
print("\n=== ğŸ… AIå‹ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (çš„ä¸­ç‡é‡è¦–) ===")
final_list_prob = df_pred.sort_values('AIå‹ç‡(%)', ascending=False)
print(final_list_prob[disp_cols].head(15))

if len(final_list_ev) > 0:
    top_ev = final_list_ev.iloc[0]
    print(f"\nğŸ’° æœŸå¾…å€¤No.1: {top_ev[name_col]} (æœŸå¾…å€¤ {top_ev['æœŸå¾…å€¤']:.2f})")
if len(final_list_prob) > 0:
    top_prob = final_list_prob.iloc[0]
    print(f"ğŸ‘‘ å‹ç‡No.1  : {top_prob[name_col]} (å‹ç‡ {top_prob['AIå‹ç‡(%)']}%)")