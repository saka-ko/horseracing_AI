# ==========================================
# ğŸ‡ ç«¶é¦¬AI (ZIæ¬ æå¯¾ç­–æ¸ˆã¿ãƒ»å®Œå…¨ç‰ˆ)
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import sys
import os
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import GroupShuffleSplit

# ------------------------------------------------
# 0. è¨­å®š
# ------------------------------------------------
train_file = 'race_5years_zi_hoseitime_kai.csv' 
entry_file = 'entry_table.csv'      

if len(sys.argv) > 1 and sys.argv[1].endswith('.csv'):
    entry_file = sys.argv[1]

# ------------------------------------------------
# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ & å¾¹åº•ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ------------------------------------------------
print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

try:
    df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
except:
    df_train = pd.read_csv(train_file, encoding='utf-8', low_memory=False)

df_train.columns = df_train.columns.str.strip()

# åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°
col_map = {}
aliases = {
    'ç€é †': ['ç¢ºå®šç€é †', 'ç€é †'],
    'ZI': ['æŒ‡æ•°', 'ZI', 'ZIå€¤'],
    'ã‚ªãƒƒã‚º': ['å˜å‹ã‚ªãƒƒã‚º', 'å˜å‹', 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'],
    'ãƒ¬ãƒ¼ã‚¹ID': ['ãƒ¬ãƒ¼ã‚¹ID(æ–°)', 'ãƒ¬ãƒ¼ã‚¹ID(æ—§)', 'ãƒ¬ãƒ¼ã‚¹ID'],
    'å‰èµ°è£œæ­£': ['å‰èµ°è£œ9', 'å‰èµ°è£œæ­£', 'å‰èµ°ã‚¿ã‚¤ãƒ '] 
}

for key, candidates in aliases.items():
    for cand in candidates:
        if cand in df_train.columns:
            col_map[key] = cand
            break

if 'ç€é †' not in col_map or 'ZI' not in col_map:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

# æ•°å€¤åŒ–
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        import re
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

df_train['target'] = (df_train[col_map['ç€é †']].apply(force_numeric) == 1).astype(int)
df_train['æŒ‡æ•°'] = df_train[col_map['ZI']].apply(force_numeric).fillna(0)
df_train['å˜å‹ã‚ªãƒƒã‚º'] = df_train[col_map['ã‚ªãƒƒã‚º']].apply(force_numeric).fillna(0)

if 'å‰èµ°è£œæ­£' in col_map:
    df_train['å‰èµ°è£œæ­£'] = df_train[col_map['å‰èµ°è£œæ­£']].apply(force_numeric).fillna(0)
else:
    df_train['å‰èµ°è£œæ­£'] = 0

# ãƒ¬ãƒ¼ã‚¹IDä¿®æ­£
rid_col = col_map['ãƒ¬ãƒ¼ã‚¹ID']
df_train['rid_str'] = df_train[rid_col].astype(str)
if len(df_train) / df_train['rid_str'].nunique() < 5.0:
    df_train['rid_group'] = df_train['rid_str'].str[:-2]
else:
    df_train['rid_group'] = df_train['rid_str']

# --- ğŸ§¹ ã“ã“ãŒä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼šã‚´ãƒŸãƒ‡ãƒ¼ã‚¿ã®æ’é™¤ ---
print("\nğŸ§¹ ãƒ‡ãƒ¼ã‚¿ã®å“è³ªãƒã‚§ãƒƒã‚¯ä¸­...")
initial_count = len(df_train)

# 1. ZIãŒ0ã®ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã™ã‚‹ï¼ˆå­¦ç¿’ã«æ‚ªå½±éŸ¿ãªãŸã‚ï¼‰
# ãŸã ã—ã€æ–°é¦¬æˆ¦ãªã©ã§å…¨é¦¬0ã®å ´åˆã¯ãƒ¬ãƒ¼ã‚¹ã”ã¨æ¶ˆã™
df_train = df_train[df_train['æŒ‡æ•°'] > 0]
cleaned_count = len(df_train)

print(f"   - å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°: {initial_count}è¡Œ")
print(f"   - ZI=0ã‚’é™¤å¤–å¾Œ: {cleaned_count}è¡Œ (å‰Šé™¤: {initial_count - cleaned_count}è¡Œ)")

if cleaned_count < 1000:
    print("âš ï¸ è­¦å‘Š: æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ã€‚ZIãŒæ­£ã—ãå‡ºåŠ›ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# ãƒ©ãƒ³ã‚¯è¨ˆç®—ï¼ˆã‚´ãƒŸæ’é™¤å¾Œã«å†è¨ˆç®—ï¼‰
df_train['æŒ‡æ•°é †ä½'] = df_train.groupby('rid_group')['æŒ‡æ•°'].rank(ascending=False, method='min')
df_train['è£œæ­£é †ä½'] = df_train.groupby('rid_group')['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

features = ['æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'æŒ‡æ•°é †ä½', 'è£œæ­£é †ä½']
X = df_train[features]
y = df_train['target']

# ------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼
# ------------------------------------------------
print("\nğŸ“Š æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å†æ¤œè¨¼ä¸­...")

# ã‚°ãƒ«ãƒ¼ãƒ—åˆ†å‰²
gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
# ãƒ‡ãƒ¼ã‚¿ãŒæ¸›ã£ã¦ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã®ã‚’é˜²ã
if df_train['rid_group'].nunique() > 1:
    train_idx, val_idx = next(gss.split(X, y, groups=df_train['rid_group']))
    
    X_train = X.iloc[train_idx]
    y_train = y.iloc[train_idx]
    X_val = X.iloc[val_idx]
    y_val = y.iloc[val_idx]
    
    df_val_sim = df_train.iloc[val_idx].copy()
    
    # å­¦ç¿’
    model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
    calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=3)
    calibrated_model.fit(X_train, y_train)
    
    # äºˆæ¸¬
    probs = calibrated_model.predict_proba(X_val)[:, 1]
    df_val_sim['prob'] = probs
    df_val_sim['expected_value'] = df_val_sim['prob'] * df_val_sim['å˜å‹ã‚ªãƒƒã‚º']
    
    # ã‚ªãƒƒã‚ºæ–­å±¤
    df_val_sim = df_val_sim.sort_values(by=['rid_group', 'å˜å‹ã‚ªãƒƒã‚º'])
    df_val_sim['next_odds'] = df_val_sim.groupby('rid_group')['å˜å‹ã‚ªãƒƒã‚º'].shift(-1)
    df_val_sim['gap_next'] = df_val_sim['next_odds'] / df_val_sim['å˜å‹ã‚ªãƒƒã‚º']
    df_val_sim['gap_next'] = df_val_sim['gap_next'].fillna(1.0)
    
    # æ¡ä»¶
    cond_zi = df_val_sim['æŒ‡æ•°é †ä½'] == 1
    idx_max_prob = df_val_sim.groupby('rid_group')['prob'].idxmax()
    cond_ai_top = df_val_sim.index.isin(idx_max_prob)
    cond_gap = (df_val_sim['expected_value'] >= 1.0) & \
               (df_val_sim['prob'] >= 0.10) & \
               (df_val_sim['gap_next'] >= 1.5)
    
    def report_sim(name, condition):
        picks = df_val_sim[condition]
        if len(picks) == 0:
            print(f"  [{name}] è©²å½“ãªã—")
            return
        hits = picks[picks['target'] == 1]
        acc = len(hits) / len(picks) * 100
        rec = hits['å˜å‹ã‚ªãƒƒã‚º'].sum() / len(picks) * 100
        avg_odds = picks['å˜å‹ã‚ªãƒƒã‚º'].mean()
        print(f"  [{name}]")
        print(f"    è³¼å…¥: {len(picks)}R / å¹³å‡ã‚ªãƒƒã‚º: {avg_odds:.1f}å€")
        print(f"    ğŸ¯ çš„ä¸­ç‡: {acc:.2f}%")
        print(f"    ğŸ’° å›åç‡: {rec:.2f}%")
    
    print(f"--- ğŸ æ¤œè¨¼çµæœ (ZIæœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿) ---")
    report_sim("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³: ZI 1ä½", cond_zi)
    print("-" * 40)
    report_sim("ãƒ—ãƒ©ãƒ³A: AIæœ¬å‘½", cond_ai_top)
    report_sim("ãƒ—ãƒ©ãƒ³B: AI + æ–­å±¤ç†è«–", cond_gap)
    print(f"--------------------------------------------------")
    
    # å†å­¦ç¿’
    print("ğŸ”„ æœ¬ç•ªç”¨ã«å…¨ãƒ‡ãƒ¼ã‚¿(ZIæœ‰åŠ¹åˆ†)ã§å†å­¦ç¿’ã—ã¦ã„ã¾ã™...")
    calibrated_model.fit(X, y)
else:
    print("âš ï¸ ã‚¨ãƒ©ãƒ¼: å­¦ç¿’ã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒæ®‹ã£ã¦ã„ã¾ã›ã‚“ã€‚")

# ------------------------------------------------
# 3. äºˆæƒ³ãƒ‘ãƒ¼ãƒˆ (çœç•¥ã›ãšè¨˜è¼‰)
# ------------------------------------------------
print(f"\nğŸš€ å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")
if not os.path.exists(entry_file):
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: äºˆæƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«({entry_file})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

df_entry.columns = df_entry.columns.str.strip()
df_pred = df_entry.copy()

hosei_cols = []
for i in range(1, 4):
    c1 = f'è£œ:{i}'; c2 = f'è£œæ­£ã‚¿ã‚¤ãƒ .{i}'
    if c1 in df_pred.columns: hosei_cols.append(c1)
    elif c2 in df_pred.columns: hosei_cols.append(c2)
if 'è£œæ­£ã‚¿ã‚¤ãƒ ' in df_pred.columns: hosei_cols.append('è£œæ­£ã‚¿ã‚¤ãƒ ')

def get_max_hosei(row):
    vals = []
    for c in hosei_cols:
        v = force_numeric(row[c])
        if v > 0: vals.append(v)
    return max(vals) if vals else 0

df_pred['å‰èµ°è£œæ­£'] = df_pred.apply(get_max_hosei, axis=1)

if 'ZI' in df_pred.columns: df_pred['æŒ‡æ•°'] = df_pred['ZI'].apply(force_numeric).fillna(0)
else: df_pred['æŒ‡æ•°'] = 0

odds_col_entry = None
for c in ['å˜å‹', 'å˜å‹ã‚ªãƒƒã‚º', 'äºˆæƒ³å˜å‹ã‚ªãƒƒã‚º']:
    if c in df_pred.columns: odds_col_entry = c; break
df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred[odds_col_entry].apply(force_numeric).fillna(0) if odds_col_entry else 0

race_key = 'ãƒ¬ãƒ¼ã‚¹å' if 'ãƒ¬ãƒ¼ã‚¹å' in df_pred.columns else 'dummy'
if race_key == 'dummy': df_pred['dummy'] = 1

df_pred['æŒ‡æ•°é †ä½'] = df_pred.groupby(race_key)['æŒ‡æ•°'].rank(ascending=False, method='min')
df_pred['è£œæ­£é †ä½'] = df_pred.groupby(race_key)['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

X_pred = df_pred[features]
raw_probs = calibrated_model.predict_proba(X_pred)[:, 1]

total_prob = raw_probs.sum()
normalized_probs = raw_probs / total_prob if total_prob > 0 else raw_probs

df_pred['AIå‹ç‡(%)'] = (normalized_probs * 100).round(2)
df_pred['æœŸå¾…å€¤'] = (normalized_probs * df_pred['å˜å‹ã‚ªãƒƒã‚º'])

# ã‚ªãƒƒã‚ºæ–­å±¤
def analyze_odds_gap(df_race):
    df_sorted = df_race[df_race['å˜å‹ã‚ªãƒƒã‚º'] > 0].sort_values('å˜å‹ã‚ªãƒƒã‚º')
    if len(df_sorted) < 6: return "âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³", []
    odds = df_sorted['å˜å‹ã‚ªãƒƒã‚º'].values
    gaps = odds[1:] / odds[:-1]
    diagnosis = []
    target_horse_indices = [] 
    if gaps[0] >= 2.5: diagnosis.append(f"ğŸ¦ 1ç•ªäººæ°—é‰„æ¿(æ–­å±¤{gaps[0]:.1f})")
    elif gaps[0] < 1.5: diagnosis.append(f"âš ï¸ 1ç•ªäººæ°—å±é™º(æ–­å±¤{gaps[0]:.1f})")
    middle_gaps = gaps[1:5] 
    if len(middle_gaps) > 0:
        max_gap_idx = np.argmax(middle_gaps) + 1 
        max_gap_val = middle_gaps[np.argmax(middle_gaps)]
        if max_gap_val >= 2.0:
            target_pop = max_gap_idx + 1
            target_name = df_sorted.iloc[max_gap_idx]['é¦¬å'] if 'é¦¬å' in df_sorted.columns else ''
            diagnosis.append(f"ğŸ’° {target_pop}ç•ªäººæ°—({target_name})ç‹™ã„ç›®(æ–­å±¤{max_gap_val:.1f})")
            target_horse_indices.append(max_gap_idx)
    if all(g < 1.5 for g in gaps[:5]): diagnosis.append("ğŸ’¤ æ··æˆ¦ã‚¹ãƒ«ãƒ¼æ¨å¥¨")
    return " / ".join(diagnosis), df_sorted.iloc[target_horse_indices]['é¦¬å'].tolist() if 'é¦¬å' in df_sorted.columns else []

gap_msg, gap_targets = analyze_odds_gap(df_pred)

cols_out = ['æ ç•ª', 'é¦¬ç•ª', 'é¦¬å', 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'æŒ‡æ•°', 'å‰èµ°è£œæ­£']
disp_cols = [c for c in cols_out if c in df_pred.columns]

print("\n=== ğŸ’° æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===")
print(df_pred[df_pred['å˜å‹ã‚ªãƒƒã‚º'] >= 1.0].sort_values('æœŸå¾…å€¤', ascending=False)[disp_cols].head(15))
print("\n=== ğŸ“Š ã‚ªãƒƒã‚ºæ–­å±¤åˆ†æ ===")
print(f"ğŸ’¬ {gap_msg}")