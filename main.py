# ==========================================
# ğŸ‡ ã‚ãªãŸå°‚ç”¨ãƒ¢ãƒ‡ãƒ«ï¼šèƒ½åŠ›ï¼†ãƒ©ãƒƒãƒ—ç‰¹åŒ–å‹AI
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import re
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.calibration import CalibratedClassifierCV

# 1. ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿
train_file = 'race_data_5years.csv'
entry_file = 'entry_table.csv'

print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")
try:
    df_train = pd.read_csv(train_file, encoding='utf-8-sig', low_memory=False)
except:
    try:
        df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
    except:
        df_train = pd.read_csv(train_file, encoding='shift_jis', errors='ignore', low_memory=False)

# 2. ç‰¹å¾´é‡ã®å³é¸ (ã‚ãªãŸãŒè¦‹ã¦ã„ã‚‹ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã®ã¿)
# ------------------------------------------------
features = [
    # --- èƒ½åŠ›è©•ä¾¡ ---
    'æŒ‡æ•°',           # ZIå€¤ï¼ˆç·åˆèƒ½åŠ›ï¼‰
    'å‰èµ°è£œæ­£',       # ã‚¹ãƒ”ãƒ¼ãƒ‰æŒ‡æ•°ï¼ˆã‚¿ã‚¤ãƒ ãƒ¬ãƒ™ãƒ«ï¼‰
    'å‰èµ°ç€é †_num',   # ç€é †
    'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ', # è² ã‘æ–¹ï¼ˆ0.1ç§’å·®ãªã‚‰é€†è»¢å¯èƒ½ãªã©ï¼‰
    
    # --- ãƒ©ãƒƒãƒ—ãƒ»å±•é–‹ ---
    'å‰èµ°PCI_val',    # ãƒšãƒ¼ã‚¹é…åˆ†ï¼ˆç¬ç™ºåŠ›oræŒä¹…åŠ›ï¼‰
    'å‰èµ°RPCI_val',   # ãƒ¬ãƒ¼ã‚¹å…¨ä½“ã®ãƒšãƒ¼ã‚¹
    'å‰èµ°Ave3F',      # å‰åŠã€œä¸­ç›¤ã®ã‚¹ãƒ”ãƒ¼ãƒ‰
    'å‰èµ°ä¸Šã‚Š3F',     # æœ«è„šã®çµ¶å¯¾å€¤
    
    # --- èˆå°è¨­å®š ---
    'ã‚³ãƒ¼ã‚¹ID'        # ã‚³ãƒ¼ã‚¹é©æ€§ï¼ˆå¿…é ˆï¼‰
]
# ------------------------------------------------

# ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        # å…¨è§’â†’åŠè§’ã€è¨˜å·å‰Šé™¤
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except:
        return np.nan

# å‰å‡¦ç†ãƒ—ãƒ­ã‚»ã‚¹
def preprocess_data(df, is_train=True):
    # åˆ—åã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
    df.columns = df.columns.str.strip()
    df = df.loc[:, ~df.columns.duplicated()]
    
    # ã‚³ãƒ¼ã‚¹IDä½œæˆ
    if 'å ´æ‰€' not in df.columns:
        if 'é–‹å‚¬' in df.columns:
            place_map = {'æœ­':'æœ­å¹Œ', 'å‡½':'å‡½é¤¨', 'ç¦':'ç¦å³¶', 'æ–°':'æ–°æ½Ÿ', 'æ±':'æ±äº¬', 'ä¸­':'ä¸­å±±', 'äº¬':'äº¬éƒ½', 'é˜ª':'é˜ªç¥', 'å°':'å°å€‰'}
            df['å ´æ‰€'] = df['é–‹å‚¬'].astype(str).apply(lambda x: place_map.get(x[1], 'ãã®ä»–') if len(x)>1 else 'ãã®ä»–')
        else:
            df['å ´æ‰€'] = 'ãã®ä»–'
    
    if 'èŠãƒ»ãƒ€' not in df.columns: df['èŠãƒ»ãƒ€'] = 'èŠ'
    if 'è·é›¢' not in df.columns: df['è·é›¢'] = 1600
    
    df['ã‚³ãƒ¼ã‚¹ID'] = df['å ´æ‰€'].astype(str) + df['èŠãƒ»ãƒ€'].astype(str) + df['è·é›¢'].astype(str)

    # æ•°å€¤é …ç›®ã®ãƒãƒƒãƒ”ãƒ³ã‚°ã¨å¤‰æ›
    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨å‡ºé¦¬è¡¨ãƒ‡ãƒ¼ã‚¿ã®åˆ—åã®é•ã„ã‚’å¸å
    if not is_train:
        rename_map = {
            'ZI': 'æŒ‡æ•°',
            'è£œæ­£ã‚¿ã‚¤ãƒ .1': 'å‰èµ°è£œæ­£', # å‡ºé¦¬è¡¨ã®éå»èµ°
            'è£œæ­£ã‚¿ã‚¤ãƒ ': 'å‰èµ°è£œæ­£',   # å¿µã®ãŸã‚
            'ç€é †.1': 'å‰èµ°ç€é †',
            'ç€å·®.1': 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ',
            'ä¸Šã‚Š3F.1': 'å‰èµ°ä¸Šã‚Š3F',
            'PCI.1': 'å‰èµ°PCI',
            'Ave-3F.1': 'å‰èµ°Ave-3F',
            'PCI': 'å‰èµ°PCI',         # å‡ºé¦¬è¡¨ã«ã‚ˆã£ã¦ã¯ã“ã“ã«å…¥ã‚‹
            'å˜å‹': 'å˜å‹ã‚ªãƒƒã‚º'
        }
        # å­˜åœ¨ã™ã‚‹åˆ—ã ã‘ãƒªãƒãƒ¼ãƒ 
        for k, v in rename_map.items():
            if k in df.columns and v not in df.columns:
                df[v] = df[k]

    # å„ç‰¹å¾´é‡ã®æ•°å€¤åŒ– (æœ€é‡è¦)
    # 1. ç€é †
    if 'ç€é †' in df.columns:
        # å­¦ç¿’ç”¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
        if is_train:
            df['ç€é †_num'] = df['ç€é †'].apply(force_numeric)
            df = df.dropna(subset=['ç€é †_num'])
            df['ç€é †_num'] = df['ç€é †_num'].astype(int)
    
    # 2. å‰èµ°ç€é †
    if 'å‰èµ°ç€é †' in df.columns: df['å‰èµ°ç€é †_num'] = df['å‰èµ°ç€é †'].apply(force_numeric)
    else: df['å‰èµ°ç€é †_num'] = np.nan

    # 3. ã‚¿ã‚¤ãƒ å·®
    if 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ' in df.columns: df['å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ '] = df['å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ '].apply(force_numeric)
    else: df['å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ '] = 0

    # 4. PCI (ãƒ©ãƒƒãƒ—)
    if 'å‰èµ°PCI' in df.columns: df['å‰èµ°PCI_val'] = df['å‰èµ°PCI'].apply(force_numeric)
    elif 'PCI.1' in df.columns: df['å‰èµ°PCI_val'] = df['PCI.1'].apply(force_numeric)
    else: df['å‰èµ°PCI_val'] = 50 # å¹³å‡

    # 5. RPCI
    if 'å‰èµ°RPCI' in df.columns: df['å‰èµ°RPCI_val'] = df['å‰èµ°RPCI'].apply(force_numeric)
    elif 'ãƒ¬ãƒ¼ã‚¹PCI.1' in df.columns: df['å‰èµ°RPCI_val'] = df['ãƒ¬ãƒ¼ã‚¹PCI.1'].apply(force_numeric)
    else: df['å‰èµ°RPCI_val'] = 50

    # 6. Ave-3F
    if 'å‰èµ°Ave-3F' in df.columns: df['å‰èµ°Ave3F'] = df['å‰èµ°Ave-3F'].apply(force_numeric)
    else: df['å‰èµ°Ave3F'] = np.nan

    # 7. ãã®ä»– (æŒ‡æ•°, è£œæ­£, ä¸ŠãŒã‚Š)
    for col in ['æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'å‰èµ°ä¸Šã‚Š3F']:
        if col in df.columns:
            df[col] = df[col].apply(force_numeric)
        else:
            df[col] = np.nan

    return df

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†å®Ÿè¡Œ
df_train = preprocess_data(df_train, is_train=True)

# ã‚³ãƒ¼ã‚¹IDã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
le_course = LabelEncoder()
df_train['ã‚³ãƒ¼ã‚¹ID'] = df_train['ã‚³ãƒ¼ã‚¹ID'].astype(str)
le_course.fit(df_train['ã‚³ãƒ¼ã‚¹ID'])
df_train['ã‚³ãƒ¼ã‚¹ID'] = le_course.transform(df_train['ã‚³ãƒ¼ã‚¹ID'])

# æ¬ æå€¤åŸ‹ã‚
for f in features:
    if f in df_train.columns:
        df_train[f] = df_train[f].fillna(df_train[f].mean())
    else:
        df_train[f] = 0

print("ğŸ”¥ ã‚ãªãŸå°‚ç”¨ãƒ¢ãƒ‡ãƒ«(èƒ½åŠ›é‡è¦–)ã‚’å­¦ç¿’ä¸­...")
X = df_train[features]
y = (df_train['ç€é †_num'] == 1).astype(int)

model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
model.fit(X, y)
print("âœ… å­¦ç¿’å®Œäº†ï¼")

# ------------------------------------------------
# 3. å‡ºé¦¬è¡¨ã§äºˆæƒ³
# ------------------------------------------------
print(f"ğŸš€ å‡ºé¦¬è¡¨({entry_file})ã‚’èª­ã¿è¾¼ã‚“ã§äºˆæƒ³ã—ã¾ã™...")
try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

# å‰å‡¦ç†
df_entry = preprocess_data(df_entry, is_train=False)

# ã‚³ãƒ¼ã‚¹IDå¤‰æ› (æœªçŸ¥ã®ã‚³ãƒ¼ã‚¹ã¯'0'æ‰±ã„)
df_entry['ã‚³ãƒ¼ã‚¹ID'] = df_entry['ã‚³ãƒ¼ã‚¹ID'].astype(str).apply(lambda x: x if x in le_course.classes_ else le_course.classes_[0])
df_entry['ã‚³ãƒ¼ã‚¹ID'] = le_course.transform(df_entry['ã‚³ãƒ¼ã‚¹ID'])

# æ¬ æåŸ‹ã‚
for f in features:
    if f in df_entry.columns:
        df_entry[f] = df_entry[f].fillna(df_train[f].mean()) # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã§åŸ‹ã‚ã‚‹
    else:
        df_entry[f] = 0

# äºˆæ¸¬
X_entry = df_entry[features]
probs = model.predict_proba(X_entry)[:, 1]
df_entry['AIå‹ç‡(%)'] = (probs * 100).round(1)

# æœŸå¾…å€¤ (ã‚ªãƒƒã‚ºãŒã‚ã‚Œã°)
if 'å˜å‹ã‚ªãƒƒã‚º' in df_entry.columns:
    df_entry['å˜å‹ã‚ªãƒƒã‚º'] = df_entry['å˜å‹ã‚ªãƒƒã‚º'].apply(force_numeric).fillna(0)
    df_entry['æœŸå¾…å€¤'] = (df_entry['AIå‹ç‡(%)'] / 100) * df_entry['å˜å‹ã‚ªãƒƒã‚º']
else:
    df_entry['å˜å‹ã‚ªãƒƒã‚º'] = 0
    df_entry['æœŸå¾…å€¤'] = 0

# é¦¬åã®å–å¾—
name_col = [c for c in df_entry.columns if 'é¦¬å' in c][0] if [c for c in df_entry.columns if 'é¦¬å' in c] else 'é¦¬å'
if name_col not in df_entry.columns: df_entry[name_col] = 'Unknown'

# çµæœè¡¨ç¤º
print("\n=== ğŸ¯ èƒ½åŠ›ï¼†ãƒ©ãƒƒãƒ—ç‰¹åŒ–å‹AI æ¨å¥¨é¦¬ ===")
out_cols = ['æ ç•ª', 'é¦¬ç•ª', name_col, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ']
# å­˜åœ¨ã™ã‚‹åˆ—ã ã‘è¡¨ç¤º
out_cols = [c for c in out_cols if c in df_entry.columns]

print(df_entry.sort_values('AIå‹ç‡(%)', ascending=False)[out_cols].head(15))

# é‡è¦åº¦ç¢ºèª
print("\n=== ã“ã®AIãŒé‡è¦–ã—ãŸãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ ===")
imp = pd.DataFrame({'feature': features, 'importance': model.feature_importances_})
print(imp.sort_values('importance', ascending=False))