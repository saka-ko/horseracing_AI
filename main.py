# ==========================================
# ğŸ‡ ç«¶é¦¬AI (ZI & è£œæ­£ã‚¿ã‚¤ãƒ  & ã‚ªãƒƒã‚ºæ–­å±¤) - æ¤œè¨¼å¼·åŒ–ç‰ˆ
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import sys
import os
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import train_test_split

# ------------------------------------------------
# 0. è¨­å®š
# ------------------------------------------------
train_file = 'race_5years_zi_hoseitime_kai.csv' 
entry_file = 'entry_table.csv'      

# ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°å¯¾å¿œ
if len(sys.argv) > 1 and sys.argv[1].endswith('.csv'):
    entry_file = sys.argv[1]

# ------------------------------------------------
# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ & ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ------------------------------------------------
print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

try:
    df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
except:
    df_train = pd.read_csv(train_file, encoding='utf-8', low_memory=False)

df_train.columns = df_train.columns.str.strip()

# --- åˆ—åãƒãƒƒãƒ”ãƒ³ã‚° ---
col_map = {}
aliases = {
    'ç€é †': ['ç¢ºå®šç€é †', 'ç€é †'],
    'ZI': ['æŒ‡æ•°', 'ZI', 'ZIå€¤'],
    'ã‚ªãƒƒã‚º': ['å˜å‹ã‚ªãƒƒã‚º', 'å˜å‹', 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'],
    'ãƒ¬ãƒ¼ã‚¹ID': ['ãƒ¬ãƒ¼ã‚¹ID(æ–°)', 'ãƒ¬ãƒ¼ã‚¹ID(æ—§)', 'ãƒ¬ãƒ¼ã‚¹ID'],
    'å‰èµ°è£œæ­£': ['å‰èµ°è£œ9', 'å‰èµ°è£œæ­£', 'å‰èµ°ã‚¿ã‚¤ãƒ '] 
}

for key, candidates in aliases.items():
    for cand in candidates:
        if cand in df_train.columns:
            col_map[key] = cand
            break

if 'ç€é †' not in col_map or 'ZI' not in col_map:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ç¾åœ¨ã®åˆ—å: {list(df_train.columns)}")
    sys.exit(1)

# æ•°å€¤åŒ–é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        import re
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

# ãƒ‡ãƒ¼ã‚¿æ•´å½¢
df_train['target'] = (df_train[col_map['ç€é †']].apply(force_numeric) == 1).astype(int)
df_train['æŒ‡æ•°'] = df_train[col_map['ZI']].apply(force_numeric).fillna(0)
df_train['å˜å‹ã‚ªãƒƒã‚º'] = df_train[col_map['ã‚ªãƒƒã‚º']].apply(force_numeric).fillna(0)

if 'å‰èµ°è£œæ­£' in col_map:
    df_train['å‰èµ°è£œæ­£'] = df_train[col_map['å‰èµ°è£œæ­£']].apply(force_numeric).fillna(0)
else:
    df_train['å‰èµ°è£œæ­£'] = 0

# ãƒ¬ãƒ¼ã‚¹IDä¿®æ­£ï¼ˆé¦¬ç•ªã‚«ãƒƒãƒˆï¼‰
rid_col = col_map['ãƒ¬ãƒ¼ã‚¹ID']
df_train['rid_str'] = df_train[rid_col].astype(str)
if len(df_train) / df_train['rid_str'].nunique() < 5.0:
    df_train['rid_group'] = df_train['rid_str'].str[:-2]
else:
    df_train['rid_group'] = df_train['rid_str']

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
df_train['æŒ‡æ•°é †ä½'] = df_train.groupby('rid_group')['æŒ‡æ•°'].rank(ascending=False, method='min')
df_train['è£œæ­£é †ä½'] = df_train.groupby('rid_group')['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

features = ['æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'æŒ‡æ•°é †ä½', 'è£œæ­£é †ä½']
X = df_train[features]
y = df_train['target']

# ------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼ï¼ˆã‚ªãƒƒã‚ºæ–­å±¤ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãï¼‰
# ------------------------------------------------
print("\nğŸ“Š ãƒ¢ãƒ‡ãƒ«ã¨ã€ã‚ªãƒƒã‚ºæ–­å±¤ç†è«–ã€ã®æ¤œè¨¼ä¸­ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚’8:2ã«åˆ†å‰²ï¼‰...")

# ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ä½œæˆ
df_val_sim = df_train.loc[X_val.index].copy()
df_val_sim['target'] = y_val

# å­¦ç¿’
model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated_model.fit(X_train, y_train)

# äºˆæ¸¬
probs = calibrated_model.predict_proba(X_val)[:, 1]
df_val_sim['prob'] = probs
# æœŸå¾…å€¤ = å‹ç‡ * ã‚ªãƒƒã‚º
df_val_sim['expected_value'] = df_val_sim['prob'] * df_val_sim['å˜å‹ã‚ªãƒƒã‚º']

# --- ğŸ¦ ã‚ªãƒƒã‚ºæ–­å±¤ã®è¨ˆç®— (é«˜é€ŸåŒ–ã®ãŸã‚ãƒ™ã‚¯ãƒˆãƒ«å‡¦ç†) ---
# ãƒ¬ãƒ¼ã‚¹IDã¨ã‚ªãƒƒã‚ºã§ã‚½ãƒ¼ãƒˆ
df_val_sim = df_val_sim.sort_values(by=['rid_group', 'å˜å‹ã‚ªãƒƒã‚º'])

# æ¬¡ã®é¦¬ã®ã‚ªãƒƒã‚ºã‚’å–å¾— (åŒã˜ãƒ¬ãƒ¼ã‚¹IDå†…ã®ã¿)
df_val_sim['next_odds'] = df_val_sim.groupby('rid_group')['å˜å‹ã‚ªãƒƒã‚º'].shift(-1)
# æ–­å±¤å€¤ã‚’è¨ˆç®— (æ¬¡ã®ã‚ªãƒƒã‚º / è‡ªåˆ†ã®ã‚ªãƒƒã‚º)
df_val_sim['gap_next'] = df_val_sim['next_odds'] / df_val_sim['å˜å‹ã‚ªãƒƒã‚º']
# NaNåŸ‹ã‚ (ä¸€ç•ªäººæ°—ã®é¦¬ãªã©)
df_val_sim['gap_next'] = df_val_sim['gap_next'].fillna(1.0)

# === ğŸ§ª ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¡ä»¶ ===
# æ¡ä»¶A: AIæ¨å¥¨ã®ã¿ (æœŸå¾…å€¤ > 1.0)
cond_ai = df_val_sim['expected_value'] >= 1.0

# æ¡ä»¶B: AIæ¨å¥¨ + æ–­å±¤ç†è«–
# ã€ŒæœŸå¾…å€¤ > 1.0ã€ã‹ã¤ã€Œç›´å¾Œã«1.5å€ä»¥ä¸Šã®æ–­å±¤ãŒã‚ã‚‹ (ï¼è‡ªåˆ†ã¯éå°è©•ä¾¡ã®å´–ã£ã·ã¡ã«ã„ã‚‹)ã€
cond_gap = (df_val_sim['expected_value'] >= 1.0) & (df_val_sim['gap_next'] >= 1.5)

# é›†è¨ˆé–¢æ•°
def report_sim(name, condition):
    picks = df_val_sim[condition]
    if len(picks) == 0:
        print(f"  [{name}] è©²å½“é¦¬ãªã—")
        return
    
    hits = picks[picks['target'] == 1]
    accuracy = len(hits) / len(picks) * 100
    return_rate = hits['å˜å‹ã‚ªãƒƒã‚º'].sum() / len(picks) * 100
    print(f"  [{name}]")
    print(f"    è³¼å…¥ãƒ¬ãƒ¼ã‚¹æ•°: {len(picks)}R")
    print(f"    ğŸ¯ çš„ä¸­ç‡: {accuracy:.2f}%")
    print(f"    ğŸ’° å›åç‡: {return_rate:.2f}%")

print(f"--- ğŸ æ¤œè¨¼çµæœ (ãƒ†ã‚¹ãƒˆæœŸé–“ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³) ---")
report_sim("ãƒ—ãƒ©ãƒ³A: å˜ç´”AIæ¨å¥¨ (æœŸå¾…å€¤100å††ä»¥ä¸Š)", cond_ai)
print("-" * 40)
report_sim("ãƒ—ãƒ©ãƒ³B: AIæ¨å¥¨ + ã‚ªãƒƒã‚ºæ–­å±¤ã‚ã‚Š (ç›´å¾Œæ–­å±¤1.5å€ä»¥ä¸Š)", cond_gap)
print(f"--------------------------------------------------")

# æœ¬ç•ªç”¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’
print("ğŸ”„ æœ¬ç•ªç”¨ã«å…¨ãƒ‡ãƒ¼ã‚¿ã§å†å­¦ç¿’ã—ã¦ã„ã¾ã™...")
calibrated_model.fit(X, y)
print("âœ… å­¦ç¿’å®Œäº†ï¼")

# ------------------------------------------------
# 3. æœ€æ–°ã‚ªãƒƒã‚ºã§ã®äºˆæƒ³ (æ–­å±¤è¨ºæ–­æ©Ÿèƒ½ä»˜ã)
# ------------------------------------------------
print(f"\nğŸš€ å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")

if not os.path.exists(entry_file):
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: äºˆæƒ³ç”¨ãƒ•ã‚¡ã‚¤ãƒ«({entry_file})ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

df_entry.columns = df_entry.columns.str.strip()
df_pred = df_entry.copy()

# éå»3èµ°ã‹ã‚‰æœ€å¤§è£œæ­£ã‚¿ã‚¤ãƒ ã‚’å–å¾—
hosei_cols = []
for i in range(1, 4):
    c1 = f'è£œ:{i}'; c2 = f'è£œæ­£ã‚¿ã‚¤ãƒ .{i}'
    if c1 in df_pred.columns: hosei_cols.append(c1)
    elif c2 in df_pred.columns: hosei_cols.append(c2)
if 'è£œæ­£ã‚¿ã‚¤ãƒ ' in df_pred.columns: hosei_cols.append('è£œæ­£ã‚¿ã‚¤ãƒ ')

def get_max_hosei(row):
    vals = []
    for c in hosei_cols:
        v = force_numeric(row[c])
        if v > 0: vals.append(v)
    return max(vals) if vals else 0

df_pred['å‰èµ°è£œæ­£'] = df_pred.apply(get_max_hosei, axis=1)

if 'ZI' in df_pred.columns: df_pred['æŒ‡æ•°'] = df_pred['ZI'].apply(force_numeric).fillna(0)
else: df_pred['æŒ‡æ•°'] = 0

odds_col_entry = None
for c in ['å˜å‹', 'å˜å‹ã‚ªãƒƒã‚º', 'äºˆæƒ³å˜å‹ã‚ªãƒƒã‚º']:
    if c in df_pred.columns: odds_col_entry = c; break
df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred[odds_col_entry].apply(force_numeric).fillna(0) if odds_col_entry else 0

race_key = 'ãƒ¬ãƒ¼ã‚¹å' if 'ãƒ¬ãƒ¼ã‚¹å' in df_pred.columns else 'dummy'
if race_key == 'dummy': df_pred['dummy'] = 1

df_pred['æŒ‡æ•°é †ä½'] = df_pred.groupby(race_key)['æŒ‡æ•°'].rank(ascending=False, method='min')
df_pred['è£œæ­£é †ä½'] = df_pred.groupby(race_key)['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

X_pred = df_pred[features]
raw_probs = calibrated_model.predict_proba(X_pred)[:, 1]

total_prob = raw_probs.sum()
normalized_probs = raw_probs / total_prob if total_prob > 0 else raw_probs

df_pred['AIå‹ç‡(%)'] = (normalized_probs * 100).round(2)
df_pred['æœŸå¾…å€¤'] = (normalized_probs * df_pred['å˜å‹ã‚ªãƒƒã‚º'])

# é¦¬åå–å¾—
name_col = 'é¦¬å' if 'é¦¬å' in df_pred.columns else df_pred.columns[0]

# è¨ºæ–­ã‚³ãƒ¡ãƒ³ãƒˆ
def make_comment(row):
    res = []
    if row['æŒ‡æ•°é †ä½'] == 1: res.append("æŒ‡æ•°1ä½")
    if row['è£œæ­£é †ä½'] == 1: res.append("èƒ½åŠ›1ä½")
    if row['æœŸå¾…å€¤'] >= 1.0: res.append("â˜…æ¨å¥¨")
    return ",".join(res) if res else "-"
df_pred['è¨ºæ–­'] = df_pred.apply(make_comment, axis=1)

# ---------------------------------------------------------
# 4. ã‚ªãƒƒã‚ºæ–­å±¤ã«ã‚ˆã‚‹ã€Œãƒ¬ãƒ¼ã‚¹æ³¢ä¹±åº¦ã€è¨ºæ–­æ©Ÿèƒ½
# ---------------------------------------------------------
def analyze_odds_gap(df_race):
    df_sorted = df_race[df_race['å˜å‹ã‚ªãƒƒã‚º'] > 0].sort_values('å˜å‹ã‚ªãƒƒã‚º')
    if len(df_sorted) < 6: return "âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³", []

    odds = df_sorted['å˜å‹ã‚ªãƒƒã‚º'].values
    gaps = odds[1:] / odds[:-1]
    
    diagnosis = []
    target_horse_indices = [] # ãƒªã‚¹ãƒˆã®indexã«å¯¾å¿œ

    # 1. 1-2äººæ°—æ–­å±¤
    if gaps[0] >= 2.5: diagnosis.append(f"ğŸ¦ 1ç•ªäººæ°—é‰„æ¿(æ–­å±¤{gaps[0]:.1f})")
    elif gaps[0] < 1.5: diagnosis.append(f"âš ï¸ 1ç•ªäººæ°—å±é™º(æ–­å±¤{gaps[0]:.1f})")

    # 2. 3-6äººæ°—ã®ä¸­ç©´æ–­å±¤
    middle_gaps = gaps[1:5] # 2-3, 3-4, 4-5, 5-6ã®é–“
    if len(middle_gaps) > 0:
        max_gap_idx = np.argmax(middle_gaps) + 1 
        max_gap_val = middle_gaps[np.argmax(middle_gaps)]
        if max_gap_val >= 2.0:
            target_pop = max_gap_idx + 1
            target_name = df_sorted.iloc[max_gap_idx][name_col]
            diagnosis.append(f"ğŸ’° {target_pop}ç•ªäººæ°—({target_name})ç‹™ã„ç›®(å¾Œç¶šã¨æ–­å±¤{max_gap_val:.1f})")
            target_horse_indices.append(max_gap_idx)
    
    if all(g < 1.5 for g in gaps[:5]):
        diagnosis.append("ğŸ’¤ æ··æˆ¦ã‚¹ãƒ«ãƒ¼æ¨å¥¨")

    return " / ".join(diagnosis), df_sorted.iloc[target_horse_indices][name_col].tolist()

# --- çµæœå‡ºåŠ› ---
cols_out = ['æ ç•ª', 'é¦¬ç•ª', name_col, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'è¨ºæ–­', 'æŒ‡æ•°', 'å‰èµ°è£œæ­£']
disp_cols = [c for c in cols_out if c in df_pred.columns]

print("\n=== ğŸ“Š ã‚ªãƒƒã‚ºæ–­å±¤åˆ†æ (ãƒãƒ¼ã‚±ãƒƒãƒˆå¿ƒç†) ===")
# ãƒ¬ãƒ¼ã‚¹ã”ã¨ã«åˆ†æï¼ˆä»Šå›ã¯ãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ã‚’1ãƒ¬ãƒ¼ã‚¹ã¨ã¿ãªã™ã‹ã€ãƒ¬ãƒ¼ã‚¹åã§ãƒ«ãƒ¼ãƒ—ã™ã‚‹ã‹ï¼‰
# ç°¡æ˜“çš„ã«ã€Œãƒ•ã‚¡ã‚¤ãƒ«å…¨ä½“ï¼1ãƒ¬ãƒ¼ã‚¹ã€ã¨ã—ã¦è¨ºæ–­ã—ã¾ã™
gap_msg, gap_targets = analyze_odds_gap(df_pred)
print(f"ğŸ’¬ {gap_msg}")
if gap_targets:
    print(f"ğŸ‘‰ æ–­å±¤ç†è«–ã®æ³¨ç›®é¦¬: {', '.join(gap_targets)}")

print("\n=== ğŸ’° æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===")
print(df_pred[df_pred['å˜å‹ã‚ªãƒƒã‚º'] >= 1.0].sort_values('æœŸå¾…å€¤', ascending=False)[disp_cols].head(15))

if len(gap_targets) > 0:
    print("\nğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã€æ–­å±¤ç†è«–ã®æ³¨ç›®é¦¬ã€ã¨ã€AIæœŸå¾…å€¤ä¸Šä½(â˜…æ¨å¥¨)ã€ãŒé‡ãªã‚Œã°ã€æœ€å¤§ã®å‹è² æ‰€ã§ã™ï¼")