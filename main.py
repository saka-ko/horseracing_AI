import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.calibration import CalibratedClassifierCV

# ==========================================
# 1. ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
# ==========================================
file_path = 'race_data_5years.csv' 

print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™... ({file_path})")
try:
    df = pd.read_csv(file_path, encoding='utf-8-sig')
except:
    try:
        df = pd.read_csv(file_path, encoding='cp932')
    except:
        df = pd.read_csv(file_path, encoding='shift_jis', errors='ignore')

print(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)}ä»¶")

# ==========================================
# 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (ç›¸å¯¾è©•ä¾¡ã®è¿½åŠ )
# ==========================================

def clean_numeric(x):
    if pd.isna(x): return np.nan
    x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
    try:
        return float(x_str)
    except ValueError:
        return np.nan

# æ•°å€¤åŒ–
df['ç€é †_num'] = df['ç€é †'].apply(clean_numeric)
df = df.dropna(subset=['ç€é †_num'])
df['ç€é †_num'] = df['ç€é †_num'].astype(int)

if 'å‰èµ°ç€é †' in df.columns:
    df['å‰èµ°ç€é †_num'] = df['å‰èµ°ç€é †'].apply(clean_numeric)
else:
    df['å‰èµ°ç€é †_num'] = np.nan

# æ•°å€¤åˆ—ã®å‡¦ç†
num_cols = ['æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'å‰PCI', 'å‰èµ°PCI', 'å‰èµ°ä¸Šã‚Š3F', 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ']
for col in num_cols:
    if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
    else:
        df[col] = np.nan # ãªã„å ´åˆã¯æ¬ æå€¤

# --------------------------------------------------------
# â˜… New: ã€Œãƒ¬ãƒ¼ã‚¹å†…åå·®å€¤ã€ã‚’è¨ˆç®—ã™ã‚‹é­”æ³•ã®é–¢æ•°
# --------------------------------------------------------
# ã€Œãã®ãƒ¬ãƒ¼ã‚¹ã®ä¸­ã§ã€ãã®é¦¬ãŒã©ã‚Œãã‚‰ã„å¼·ã„ã‹ã€ã‚’æ•°å€¤åŒ–ã—ã¾ã™
def calculate_deviation(series):
    mean = series.mean()
    std = series.std()
    if std == 0 or pd.isna(std):
        return 50.0 # å·®ãŒãªã„å ´åˆã¯åå·®å€¤50
    return 50.0 + 10.0 * (series - mean) / std

race_id_col = 'ãƒ¬ãƒ¼ã‚¹ID(æ–°)' if 'ãƒ¬ãƒ¼ã‚¹ID(æ–°)' in df.columns else 'ãƒ¬ãƒ¼ã‚¹ID'

if race_id_col in df.columns:
    print("ç›¸å¯¾è©•ä¾¡(åå·®å€¤)ã‚’è¨ˆç®—ä¸­... ã“ã‚ŒãŒåŠ¹ãã¾ã™ï¼")
    # æŒ‡æ•°ã®åå·®å€¤ï¼ˆãƒ¡ãƒ³ãƒãƒ¼å†…ã§ã©ã‚Œã ã‘æŠœã‘ã¦ã„ã‚‹ã‹ï¼‰
    df['æŒ‡æ•°_åå·®å€¤'] = df.groupby(race_id_col)['æŒ‡æ•°'].transform(calculate_deviation).fillna(50)
    
    # å‰èµ°è£œæ­£ã®åå·®å€¤ï¼ˆã‚¹ãƒ”ãƒ¼ãƒ‰ã®ç›¸å¯¾è©•ä¾¡ï¼‰
    df['è£œæ­£_åå·®å€¤'] = df.groupby(race_id_col)['å‰èµ°è£œæ­£'].transform(calculate_deviation).fillna(50)
    
    # ä¸ŠãŒã‚Š3Fã®åå·®å€¤ï¼ˆã“ã®ãƒ¡ãƒ³ãƒãƒ¼ã®ä¸­ã§ã‚­ãƒ¬ã‚‹ã‹ã©ã†ã‹ã€‚â€»ã‚¿ã‚¤ãƒ ã¯å°ã•ã„æ–¹ãŒè‰¯ã„ã®ã§æ­£è² é€†è»¢ï¼‰
    # é€Ÿã„ã»ã†ãŒåå·®å€¤é«˜ããªã‚‹ã‚ˆã†ã« -1 ã‚’ã‹ã‘ã‚‹
    df['ä¸Šã‚Š_åå·®å€¤'] = df.groupby(race_id_col)['å‰èµ°ä¸Šã‚Š3F'].transform(
        lambda x: calculate_deviation(-x)
    ).fillna(50)
else:
    print("â€»ãƒ¬ãƒ¼ã‚¹IDãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ç›¸å¯¾è©•ä¾¡è¨ˆç®—ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸ")
    df['æŒ‡æ•°_åå·®å€¤'] = 50
    df['è£œæ­£_åå·®å€¤'] = 50
    df['ä¸Šã‚Š_åå·®å€¤'] = 50

# --- ãã®ä»–ã®ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ ---
# PCIçµ±ä¸€
df['å‰èµ°PCI_val'] = df['å‰PCI'] if 'å‰PCI' in df.columns else df['å‰èµ°PCI'] if 'å‰èµ°PCI' in df.columns else 50
# IDä½œæˆ
df['ã‚³ãƒ¼ã‚¹ID'] = df['å ´æ‰€'].astype(str) + df['èŠãƒ»ãƒ€'].astype(str) + df['è·é›¢'].astype(str)
df['é¨æ‰‹èª¿æ•™å¸«ã‚³ãƒ³ãƒ“'] = df['é¨æ‰‹ã‚³ãƒ¼ãƒ‰'].astype(str) + "_" + df['èª¿æ•™å¸«ã‚³ãƒ¼ãƒ‰'].astype(str)
if 'é¨æ‰‹ã‚³ãƒ¼ãƒ‰' in df.columns and 'å‰èµ°é¨æ‰‹ã‚³ãƒ¼ãƒ‰' in df.columns:
    df['é¨æ‰‹ç¶™ç¶šãƒ•ãƒ©ã‚°'] = (df['é¨æ‰‹ã‚³ãƒ¼ãƒ‰'] == df['å‰èµ°é¨æ‰‹ã‚³ãƒ¼ãƒ‰']).astype(int)
else:
    df['é¨æ‰‹ç¶™ç¶šãƒ•ãƒ©ã‚°'] = 0

# --- Features ---
features = [
    'æŒ‡æ•°_åå·®å€¤',    # â˜…æœ€å¼·ã®æ–°è¦è¿½åŠ 
    'è£œæ­£_åå·®å€¤',    # â˜…æœ€å¼·ã®æ–°è¦è¿½åŠ 
    'ä¸Šã‚Š_åå·®å€¤',    # â˜…æœ€å¼·ã®æ–°è¦è¿½åŠ 
    'æŒ‡æ•°', 'å‰èµ°è£œæ­£', 
    'å‰èµ°PCI_val', 
    'å‰èµ°ç€é †_num', 'å‰èµ°äººæ°—', 'å‰èµ°å˜å‹ã‚ªãƒƒã‚º', 'å‰èµ°ä¸Šã‚Š3F', 'å‰èµ°ç€å·®ã‚¿ã‚¤ãƒ ',
    'é¨æ‰‹ç¶™ç¶šãƒ•ãƒ©ã‚°', 'é¨æ‰‹èª¿æ•™å¸«ã‚³ãƒ³ãƒ“', 'ã‚³ãƒ¼ã‚¹ID',
    'æ–¤é‡', 'é¦¬ç•ª', 'é¦¬ä½“é‡', 'é¦¬ä½“é‡å¢—æ¸›', 'å¹´é½¢', 'é–“éš”', 'ç¨®ç‰¡é¦¬', 'å ´æ‰€', 'èŠãƒ»ãƒ€', 'è·é›¢'
]
features = [f for f in features if f in df.columns]

# --- Encoding ---
categorical_cols = ['å ´æ‰€', 'èŠãƒ»ãƒ€', 'é¦¬å ´çŠ¶æ…‹', 'ç¨®ç‰¡é¦¬', 'é¨æ‰‹ã‚³ãƒ¼ãƒ‰', 'èª¿æ•™å¸«ã‚³ãƒ¼ãƒ‰', 
                    'å‰èµ°èŠãƒ»ãƒ€', 'ã‚³ãƒ¼ã‚¹ID', 'é¨æ‰‹èª¿æ•™å¸«ã‚³ãƒ³ãƒ“']
encoders = {}
for col in categorical_cols:
    if col in df.columns:
        le = LabelEncoder()
        df[col] = df[col].fillna('unknown').astype(str)
        df[col] = le.fit_transform(df[col])
        encoders[col] = le

num_features = [f for f in features if f not in categorical_cols]
for col in num_features:
    if col in df.columns:
        temp_col = pd.to_numeric(df[col], errors='coerce')
        df[col] = temp_col.fillna(temp_col.mean())

# ==========================================
# 3. ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ (åå·®å€¤å…¥ã‚Š)
# ==========================================
df['target_win'] = (df['ç€é †_num'] == 1).astype(int)
X = df[features]
y = df['target_win']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("\nå­¦ç¿’é–‹å§‹... (ç›¸å¯¾è©•ä¾¡ã‚’å­¦ç¿’ä¸­)")

base_model = lgb.LGBMClassifier(
    random_state=42, 
    n_estimators=120, # å°‘ã—å¢—ã‚„ã™
    min_child_samples=30,
    num_leaves=40,
    n_jobs=-1
)

calibrated_model = CalibratedClassifierCV(base_model, method='isotonic', cv=3)
calibrated_model.fit(X_train, y_train)

# é‡è¦åº¦ç¢ºèªç”¨
base_model.fit(X_train, y_train)

# ==========================================
# 4. ã‚°ãƒªãƒƒãƒ‰ã‚µãƒ¼ãƒ (å¿…å‹æ³•æ¢ã—)
# ==========================================
prob_win = calibrated_model.predict_proba(X_test)[:, 1]
results = X_test.copy()
results['é¦¬å'] = df.loc[X_test.index, 'é¦¬å']
results['ç€é †'] = df.loc[X_test.index, 'ç€é †_num']
results['å˜å‹ã‚ªãƒƒã‚º'] = pd.to_numeric(df.loc[X_test.index, 'å˜å‹ã‚ªãƒƒã‚º'], errors='coerce').fillna(0)
results['AIå‹ç‡äºˆæ¸¬(%)'] = (prob_win * 100)
results['æœŸå¾…å€¤'] = (results['AIå‹ç‡äºˆæ¸¬(%)'] / 100) * results['å˜å‹ã‚ªãƒƒã‚º']

print("\nğŸš€ æ–°ãƒ¢ãƒ‡ãƒ«ã§æœ€é©ãªè²·ã„æ¡ä»¶ã‚’æ¢ç´¢ä¸­...")

best_strategies = []
min_odds_list = [5.0, 10.0, 15.0]
max_odds_list = [20.0, 30.0, 50.0, 100.0]
min_exp_list = [0.8, 1.0, 1.2, 1.5]

for min_odds in min_odds_list:
    for max_odds in max_odds_list:
        if min_odds >= max_odds: continue
        for min_exp in min_exp_list:
            target = results[
                (results['å˜å‹ã‚ªãƒƒã‚º'] >= min_odds) & 
                (results['å˜å‹ã‚ªãƒƒã‚º'] < max_odds) &
                (results['æœŸå¾…å€¤'] >= min_exp)
            ]
            count = len(target)
            if count < 50: continue 
            
            invest = count * 100
            ret = target[target['ç€é †'] == 1]['å˜å‹ã‚ªãƒƒã‚º'].sum() * 100
            rate = (ret / invest) * 100
            profit = ret - invest
            
            if rate >= 95: # ãƒãƒ¼ãƒ‰ãƒ«ã‚’å°‘ã—ä¸‹ã’ã¦å‚¾å‘ã‚’è¦‹ã‚‹
                best_strategies.append({
                    'ã‚ªãƒƒã‚º': f"{min_odds}-{max_odds}",
                    'æœŸå¾…å€¤': f"{min_exp}ä»¥ä¸Š",
                    'ä»¶æ•°': count,
                    'å›åç‡': f"{rate:.1f}%",
                    'åæ”¯': profit
                })

if len(best_strategies) > 0:
    strategy_df = pd.DataFrame(best_strategies)
    print("\n=== ğŸ† å›åç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (åå·®å€¤å°å…¥å¾Œ) ===")
    print(strategy_df.sort_values('åæ”¯', ascending=False).head(15))
else:
    print("\næ¡ä»¶ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸãŒã€é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„â†“")

print("\n=== é‡è¦åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===")
importance = pd.DataFrame({'feature': features, 'importance': base_model.feature_importances_})
print(importance.sort_values('importance', ascending=False).head(10))