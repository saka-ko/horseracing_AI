# ==========================================
# ğŸ‡ ç«¶é¦¬AI (ZI & æ–­å±¤ & ç‰¹å¾´é‡å¼·åŒ–ç‰ˆ)
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import sys
import os
from sklearn.calibration import CalibratedClassifierCV
from sklearn.model_selection import GroupShuffleSplit
from sklearn.preprocessing import LabelEncoder

# ------------------------------------------------
# 0. è¨­å®š
# ------------------------------------------------
train_file = 'race_5years_zi_hoseitime_kai.csv' 
entry_file = 'entry_table.csv'      

if len(sys.argv) > 1 and sys.argv[1].endswith('.csv'):
    entry_file = sys.argv[1]

# ------------------------------------------------
# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ & ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
# ------------------------------------------------
print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

try:
    df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
except:
    df_train = pd.read_csv(train_file, encoding='utf-8', low_memory=False)

df_train.columns = df_train.columns.str.strip()

# åˆ—åãƒãƒƒãƒ”ãƒ³ã‚°
col_map = {}
aliases = {
    'ç€é †': ['ç¢ºå®šç€é †', 'ç€é †'],
    'ZI': ['æŒ‡æ•°', 'ZI', 'ZIå€¤'],
    'ã‚ªãƒƒã‚º': ['å˜å‹ã‚ªãƒƒã‚º', 'å˜å‹', 'ç¢ºå®šå˜å‹ã‚ªãƒƒã‚º'],
    'ãƒ¬ãƒ¼ã‚¹ID': ['ãƒ¬ãƒ¼ã‚¹ID(æ–°)', 'ãƒ¬ãƒ¼ã‚¹ID(æ—§)', 'ãƒ¬ãƒ¼ã‚¹ID'],
    'å‰èµ°è£œæ­£': ['å‰èµ°è£œ9', 'å‰èµ°è£œæ­£', 'å‰èµ°ã‚¿ã‚¤ãƒ '] 
}

for key, candidates in aliases.items():
    for cand in candidates:
        if cand in df_train.columns:
            col_map[key] = cand
            break

if 'ç€é †' not in col_map or 'ZI' not in col_map:
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: å¿…è¦ãªåˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

# æ•°å€¤åŒ–é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        import re
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

df_train['target'] = (df_train[col_map['ç€é †']].apply(force_numeric) == 1).astype(int)
df_train['æŒ‡æ•°'] = df_train[col_map['ZI']].apply(force_numeric).fillna(0)
df_train['å˜å‹ã‚ªãƒƒã‚º'] = df_train[col_map['ã‚ªãƒƒã‚º']].apply(force_numeric).fillna(0)

if 'å‰èµ°è£œæ­£' in col_map:
    df_train['å‰èµ°è£œæ­£'] = df_train[col_map['å‰èµ°è£œæ­£']].apply(force_numeric).fillna(0)
else:
    df_train['å‰èµ°è£œæ­£'] = 0

# ZI=0ã®é™¤å¤– (å“è³ªå‘ä¸Šã®ã‚«ã‚®)
df_train = df_train[df_train['æŒ‡æ•°'] > 0]

# ãƒ¬ãƒ¼ã‚¹IDä¿®æ­£
rid_col = col_map['ãƒ¬ãƒ¼ã‚¹ID']
df_train['rid_str'] = df_train[rid_col].astype(str)
df_train['rid_group'] = df_train['rid_str'].str[:-2]

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
df_train['æŒ‡æ•°é †ä½'] = df_train.groupby('rid_group')['æŒ‡æ•°'].rank(ascending=False, method='min')
df_train['è£œæ­£é †ä½'] = df_train.groupby('rid_group')['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

# --- â˜…ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (ã“ã“ãŒé€²åŒ–) ---
# ã‚«ãƒ†ã‚´ãƒªå¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ç”¨è¾æ›¸
encoders = {}

def get_encoder(col_name, df):
    le = LabelEncoder()
    # æ¬ æå€¤ã‚’åŸ‹ã‚ã¦æ–‡å­—åˆ—åŒ–
    filled = df[col_name].fillna('Unknown').astype(str)
    le.fit(filled)
    return le

cat_cols = ['å ´æ‰€', 'é¦¬å ´çŠ¶æ…‹', 'å¤©æ°—']
for col in cat_cols:
    if col in df_train.columns:
        encoders[col] = get_encoder(col, df_train)
        df_train[col + '_enc'] = encoders[col].transform(df_train[col].fillna('Unknown').astype(str))
    else:
        df_train[col + '_enc'] = 0

# æ•°å€¤ç³»ç‰¹å¾´é‡
if 'æ–¤é‡' in df_train.columns:
    df_train['æ–¤é‡'] = df_train['æ–¤é‡'].apply(force_numeric).fillna(55)
else:
    df_train['æ–¤é‡'] = 55

if 'é¦¬ä½“é‡' in df_train.columns:
    df_train['é¦¬ä½“é‡'] = df_train['é¦¬ä½“é‡'].apply(force_numeric).fillna(480)
else:
    df_train['é¦¬ä½“é‡'] = 480

if 'é¦¬ä½“é‡å¢—æ¸›' in df_train.columns:
    def parse_weight_change(x):
        if pd.isna(x): return 0
        try:
            x = str(x).replace(' ', '') # ç©ºç™½é™¤å»
            return float(x)
        except: return 0
    df_train['é¦¬ä½“é‡å¢—æ¸›_num'] = df_train['é¦¬ä½“é‡å¢—æ¸›'].apply(parse_weight_change)
else:
    df_train['é¦¬ä½“é‡å¢—æ¸›_num'] = 0

# å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹å…¨ç‰¹å¾´é‡
features = [
    'æŒ‡æ•°', 'å‰èµ°è£œæ­£', 'æŒ‡æ•°é †ä½', 'è£œæ­£é †ä½',
    'å ´æ‰€_enc', 'é¦¬å ´çŠ¶æ…‹_enc', 'å¤©æ°—_enc',
    'æ–¤é‡', 'é¦¬ä½“é‡', 'é¦¬ä½“é‡å¢—æ¸›_num'
]

X = df_train[features]
y = df_train['target']

# ------------------------------------------------
# 2. ãƒ¢ãƒ‡ãƒ«æ¤œè¨¼
# ------------------------------------------------
print("\nğŸ“Š é€²åŒ–ã—ãŸAIãƒ¢ãƒ‡ãƒ«ã‚’æ¤œè¨¼ä¸­...")

if df_train['rid_group'].nunique() > 1:
    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
    train_idx, val_idx = next(gss.split(X, y, groups=df_train['rid_group']))
    
    X_train = X.iloc[train_idx]; y_train = y.iloc[train_idx]
    X_val = X.iloc[val_idx]; y_val = y.iloc[val_idx]
    df_val_sim = df_train.iloc[val_idx].copy()
    
    model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
    calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=3)
    calibrated_model.fit(X_train, y_train)
    
    probs = calibrated_model.predict_proba(X_val)[:, 1]
    df_val_sim['prob'] = probs
    df_val_sim['expected_value'] = df_val_sim['prob'] * df_val_sim['å˜å‹ã‚ªãƒƒã‚º']
    
    # æ–­å±¤è¨ˆç®—
    df_val_sim = df_val_sim.sort_values(by=['rid_group', 'å˜å‹ã‚ªãƒƒã‚º'])
    df_val_sim['next_odds'] = df_val_sim.groupby('rid_group')['å˜å‹ã‚ªãƒƒã‚º'].shift(-1)
    df_val_sim['gap_next'] = df_val_sim['next_odds'] / df_val_sim['å˜å‹ã‚ªãƒƒã‚º']
    df_val_sim['gap_next'] = df_val_sim['gap_next'].fillna(1.0)
    
    # æ¤œè¨¼æ¡ä»¶
    cond_zi = df_val_sim['æŒ‡æ•°é †ä½'] == 1
    # cond_ai_top = df_val_sim.groupby('rid_group')['prob'].transform(max) == df_val_sim['prob']
    idx_max_prob = df_val_sim.groupby('rid_group')['prob'].idxmax()
    cond_ai_top = df_val_sim.index.isin(idx_max_prob)
    
    cond_gap = (df_val_sim['expected_value'] >= 1.0) & \
               (df_val_sim['prob'] >= 0.10) & \
               (df_val_sim['gap_next'] >= 1.5)
    
    def report_sim(name, condition):
        picks = df_val_sim[condition]
        if len(picks) == 0: return
        hits = picks[picks['target'] == 1]
        acc = len(hits) / len(picks) * 100
        rec = hits['å˜å‹ã‚ªãƒƒã‚º'].sum() / len(picks) * 100
        print(f"  [{name}] Acc: {acc:.2f}% / Rec: {rec:.2f}%")
    
    print("--- ğŸ æ¤œè¨¼çµæœ (ZIæœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿ã®ã¿) ---")
    report_sim("ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³(ZI 1ä½)", cond_zi)
    report_sim("ãƒ—ãƒ©ãƒ³A(AIæœ¬å‘½)", cond_ai_top)
    report_sim("ãƒ—ãƒ©ãƒ³B(AI+æ–­å±¤)", cond_gap)
    print("-" * 40)
    
    # å†å­¦ç¿’
    print("ğŸ”„ æœ¬ç•ªç”¨ã«å†å­¦ç¿’ä¸­...")
    calibrated_model.fit(X, y)
else:
    print("ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®ãŸã‚å­¦ç¿’ã‚¹ã‚­ãƒƒãƒ—")
    sys.exit()

# ------------------------------------------------
# 3. äºˆæƒ³ãƒ‘ãƒ¼ãƒˆ (ç‰¹å¾´é‡è¿½åŠ ç‰ˆ)
# ------------------------------------------------
print(f"\nğŸš€ å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")
if not os.path.exists(entry_file): 
    print(f"âŒ ã‚¨ãƒ©ãƒ¼: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {entry_file}")
    sys.exit(1)

try:
    # ã¾ãšUTF-8ã§è©¦ã™
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        # ã ã‚ãªã‚‰CP932ï¼ˆShift-JISæ‹¡å¼µï¼‰ã§è©¦ã™
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        # ãã‚Œã§ã‚‚ã ã‚ãªã‚‰Shift-JISã§è©¦ã™
        df_entry = pd.read_csv(entry_file, encoding='shift_jis')

df_entry.columns = df_entry.columns.str.strip()
df_pred = df_entry.copy()

# --- ç‰¹å¾´é‡ä½œæˆï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜å‡¦ç†ï¼‰---
hosei_cols = []
for i in range(1, 4):
    c1 = f'è£œ:{i}'; c2 = f'è£œæ­£ã‚¿ã‚¤ãƒ .{i}'
    if c1 in df_pred.columns: hosei_cols.append(c1)
    elif c2 in df_pred.columns: hosei_cols.append(c2)
if 'è£œæ­£ã‚¿ã‚¤ãƒ ' in df_pred.columns: hosei_cols.append('è£œæ­£ã‚¿ã‚¤ãƒ ')

def get_max_hosei(row):
    vals = []
    for c in hosei_cols:
        v = force_numeric(row[c])
        if v > 0: vals.append(v)
    return max(vals) if vals else 0
df_pred['å‰èµ°è£œæ­£'] = df_pred.apply(get_max_hosei, axis=1)

if 'ZI' in df_pred.columns: df_pred['æŒ‡æ•°'] = df_pred['ZI'].apply(force_numeric).fillna(0)
else: df_pred['æŒ‡æ•°'] = 0

race_key = 'ãƒ¬ãƒ¼ã‚¹å' if 'ãƒ¬ãƒ¼ã‚¹å' in df_pred.columns else 'dummy'
if race_key == 'dummy': df_pred['dummy'] = 1
df_pred['æŒ‡æ•°é †ä½'] = df_pred.groupby(race_key)['æŒ‡æ•°'].rank(ascending=False, method='min')
df_pred['è£œæ­£é †ä½'] = df_pred.groupby(race_key)['å‰èµ°è£œæ­£'].rank(ascending=False, method='min')

# ã‚«ãƒ†ã‚´ãƒªãƒ»æ•°å€¤å¤‰æ›
for col in cat_cols:
    # å­¦ç¿’æ™‚ã«è¦‹ãŸã“ã¨ãŒãªã„ã‚«ãƒ†ã‚´ãƒªã¯ 'Unknown' æ‰±ã„ã«ã™ã‚‹å¯¾å¿œãŒå¿…è¦ã ãŒã€
    # LabelEncoderã¯æœªçŸ¥ã®å€¤ã«å¼±ã„ãŸã‚ã€ç°¡æ˜“çš„ã« fit æ™‚ã®ã‚¯ãƒ©ã‚¹ã‚’ä½¿ã†ã‹ 0 ã«ã™ã‚‹
    if col in df_pred.columns:
        # å®‰å…¨ç­–: mapã‚’ä½¿ã£ã¦å¤‰æ›ã—ã€ãªã‘ã‚Œã°0
        mapping = dict(zip(encoders[col].classes_, encoders[col].transform(encoders[col].classes_)))
        df_pred[col + '_enc'] = df_pred[col].astype(str).map(mapping).fillna(0)
    else:
        df_pred[col + '_enc'] = 0

if 'æ–¤é‡' in df_pred.columns: df_pred['æ–¤é‡'] = df_pred['æ–¤é‡'].apply(force_numeric).fillna(55)
else: df_pred['æ–¤é‡'] = 55

if 'é¦¬ä½“é‡' in df_pred.columns: df_pred['é¦¬ä½“é‡'] = df_pred['é¦¬ä½“é‡'].apply(force_numeric).fillna(480)
else: df_pred['é¦¬ä½“é‡'] = 480

if 'é¦¬ä½“é‡å¢—æ¸›' in df_pred.columns:
    def parse_weight(x):
        try: return float(str(x).replace(' ',''))
        except: return 0
    df_pred['é¦¬ä½“é‡å¢—æ¸›_num'] = df_pred['é¦¬ä½“é‡å¢—æ¸›'].apply(parse_weight)
else: df_pred['é¦¬ä½“é‡å¢—æ¸›_num'] = 0

# äºˆæ¸¬
X_pred = df_pred[features]
raw_probs = calibrated_model.predict_proba(X_pred)[:, 1]

# ã‚ªãƒƒã‚ºå‡¦ç†
odds_col_entry = None
for c in ['å˜å‹', 'å˜å‹ã‚ªãƒƒã‚º', 'äºˆæƒ³å˜å‹ã‚ªãƒƒã‚º']:
    if c in df_pred.columns: odds_col_entry = c; break
df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred[odds_col_entry].apply(force_numeric).fillna(0) if odds_col_entry else 0

total_prob = raw_probs.sum()
norm_probs = raw_probs / total_prob if total_prob > 0 else raw_probs
df_pred['AIå‹ç‡(%)'] = (norm_probs * 100).round(2)
df_pred['æœŸå¾…å€¤'] = (norm_probs * df_pred['å˜å‹ã‚ªãƒƒã‚º'])

# ã‚ªãƒƒã‚ºæ–­å±¤ & å‡ºåŠ›
def analyze_odds_gap(df_race):
    df_sorted = df_race[df_race['å˜å‹ã‚ªãƒƒã‚º'] > 0].sort_values('å˜å‹ã‚ªãƒƒã‚º')
    if len(df_sorted) < 6: return "", []
    odds = df_sorted['å˜å‹ã‚ªãƒƒã‚º'].values
    gaps = odds[1:] / odds[:-1]
    diag = []; targets = []
    if gaps[0] >= 2.5: diag.append(f"ğŸ¦ 1äººæ°—é‰„æ¿(æ–­å±¤{gaps[0]:.1f})")
    elif gaps[0] < 1.5: diag.append(f"âš ï¸ 1äººæ°—å±é™º(æ–­å±¤{gaps[0]:.1f})")
    
    mid_gaps = gaps[1:5]
    if len(mid_gaps) > 0:
        idx = np.argmax(mid_gaps)
        val = mid_gaps[idx]
        if val >= 2.0:
            t_idx = idx + 1
            name = df_sorted.iloc[t_idx]['é¦¬å'] if 'é¦¬å' in df_sorted.columns else ''
            diag.append(f"ğŸ’° {t_idx+1}äººæ°—({name})ç‹™ã„(æ–­å±¤{val:.1f})")
            targets.append(name)
            
    if all(g < 1.5 for g in gaps[:5]): diag.append("ğŸ’¤ æ··æˆ¦")
    return " / ".join(diag), targets

gap_msg, gap_targets = analyze_odds_gap(df_pred)
name_col = 'é¦¬å' if 'é¦¬å' in df_pred.columns else df_pred.columns[0]

def make_cmt(row):
    res = []
    if row['æŒ‡æ•°é †ä½']==1: res.append("ZI1ä½")
    if row['æœŸå¾…å€¤']>=1.0: res.append("â˜…æ¨å¥¨")
    if row[name_col] in gap_targets: res.append("ğŸ’°æ–­å±¤ç†è«–")
    return ",".join(res) if res else "-"
df_pred['è¨ºæ–­'] = df_pred.apply(make_cmt, axis=1)

cols = ['æ ç•ª', 'é¦¬ç•ª', name_col, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'è¨ºæ–­', 'æŒ‡æ•°']
disp = [c for c in cols if c in df_pred.columns]

print("\n=== ğŸ’° æœ€çµ‚äºˆæƒ³ (ZI x æ–­å±¤ x AIè£œæ­£) ===")
print(df_pred[df_pred['å˜å‹ã‚ªãƒƒã‚º']>=1.0].sort_values('æœŸå¾…å€¤', ascending=False)[disp].head(15))
print(f"\nğŸ’¬ æ–­å±¤è¨ºæ–­: {gap_msg}")