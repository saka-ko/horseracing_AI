# ==========================================
# ğŸ‡ ç«¶é¦¬AI (éå»3èµ°Maxè©•ä¾¡ & å‹ç‡è¡¨ç¤ºç‰ˆ)
# ==========================================
import pandas as pd
import numpy as np
import lightgbm as lgb
import re
from sklearn.model_selection import train_test_split
from sklearn.calibration import CalibratedClassifierCV
from sklearn.preprocessing import LabelEncoder

# ãƒ•ã‚¡ã‚¤ãƒ«è¨­å®š
train_file = 'race_5years_zi_hoseitime_kai.csv'
entry_file = 'entry_table.csv'

# æ•°å€¤åŒ–é–¢æ•°
def force_numeric(x):
    if pd.isna(x): return np.nan
    try:
        x_str = str(x).translate(str.maketrans({chr(0xFF10 + i): chr(0x30 + i) for i in range(10)}))
        clean_str = re.sub(r'[^\d.-]', '', x_str)
        return float(clean_str)
    except: return np.nan

# ------------------------------------------------
# 1. å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ & ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
# ------------------------------------------------
print(f"ğŸ”„ å­¦ç¿’ãƒ‡ãƒ¼ã‚¿({train_file})ã‚’èª­ã¿è¾¼ã‚“ã§ã„ã¾ã™...")

# èª­ã¿è¾¼ã¿
try:
    df_train = pd.read_csv(train_file, encoding='utf-8-sig', low_memory=False)
except:
    try:
        df_train = pd.read_csv(train_file, encoding='cp932', low_memory=False)
    except:
        df_train = pd.read_csv(train_file, encoding='shift_jis', errors='ignore', low_memory=False)

# åˆ—åã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°
df_train.columns = df_train.columns.str.strip()
df_train = df_train.loc[:, ~df_train.columns.duplicated()]

# ç€é †ã®ç¢ºä¿
if 'ç€é †' not in df_train.columns and 'ç¢ºå®šç€é †' in df_train.columns:
    df_train['ç€é †'] = df_train['ç¢ºå®šç€é †']

df_train['ç€é †_num'] = df_train['ç€é †'].apply(force_numeric)
df_train = df_train.dropna(subset=['ç€é †_num'])
df_train['target'] = (df_train['ç€é †_num'] == 1).astype(int)

# --- â˜…é‡è¦: éå»3èµ°ã®æœ€å¤§è£œæ­£ã‚¿ã‚¤ãƒ ã‚’è¨ˆç®— ---
print("ğŸ“Š éå»5å¹´åˆ†ã®ãƒ¬ãƒ¼ã‚¹å±¥æ­´ã‹ã‚‰ã€å„é¦¬ã®ã€éå»3èµ°MAXè£œæ­£ã€ã‚’ç®—å‡ºä¸­...")

# æ—¥ä»˜é †ã«ä¸¦ã¹ã‚‹
if 'æ—¥ä»˜(yyyy.mm.dd)' in df_train.columns:
    df_train['date'] = pd.to_datetime(df_train['æ—¥ä»˜(yyyy.mm.dd)'], errors='coerce')
else:
    # æ—¥ä»˜ãŒãªã„å ´åˆã¯ä¸¦ã³é †ã‚’ä¿¡ã˜ã‚‹ã—ã‹ãªã„ãŒã€é€šå¸¸ã¯ã‚ã‚‹ã¯ãš
    df_train['date'] = df_train.index

# è£œæ­£ã‚¿ã‚¤ãƒ ã‚’æ•°å€¤åŒ–
if 'è£œæ­£' in df_train.columns:
    df_train['è£œæ­£_val'] = df_train['è£œæ­£'].apply(force_numeric).fillna(0)
else:
    df_train['è£œæ­£_val'] = 0

# é¦¬åã¨æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
df_train = df_train.sort_values(['é¦¬å', 'date'])

# éå»3èµ°ã®æœ€å¤§å€¤ã‚’å–å¾— (ã‚·ãƒ•ãƒˆã—ã¦éå»ã‚’å‚ç…§)
# shift(1)ã§ã€Œä»Šå›ã€ã‚’å«ã‚ãªã„ã‚ˆã†ã«ã—ã€rolling(3)ã§éå»3ã¤ã‚’è¦‹ã‚‹
df_train['éå»3èµ°MAXè£œæ­£'] = df_train.groupby('é¦¬å')['è£œæ­£_val'].transform(
    lambda x: x.shift(1).rolling(window=3, min_periods=1).max()
).fillna(0)

# æŒ‡æ•° (ZI)
if 'æŒ‡æ•°' not in df_train.columns:
    if 'ZI' in df_train.columns: df_train['æŒ‡æ•°'] = df_train['ZI']
    else: df_train['æŒ‡æ•°'] = 0
df_train['æŒ‡æ•°'] = df_train['æŒ‡æ•°'].apply(force_numeric).fillna(0)

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
race_id_col = 'ãƒ¬ãƒ¼ã‚¹ID(æ–°)' if 'ãƒ¬ãƒ¼ã‚¹ID(æ–°)' in df_train.columns else 'ãƒ¬ãƒ¼ã‚¹ID'
if race_id_col not in df_train.columns:
    # IDãŒãªã„å ´åˆã¯æ—¥ä»˜ã¨å ´æ‰€ã§ä»£ç”¨
    if 'æ—¥ä»˜(yyyy.mm.dd)' in df_train.columns and 'å ´æ‰€' in df_train.columns:
         df_train['rid'] = df_train['æ—¥ä»˜(yyyy.mm.dd)'].astype(str) + df_train['å ´æ‰€']
         race_id_col = 'rid'
    else:
         race_id_col = None

if race_id_col:
    df_train['æŒ‡æ•°é †ä½'] = df_train.groupby(race_id_col)['æŒ‡æ•°'].rank(ascending=False, method='min')
    # éå»3èµ°MAXã§ã®é †ä½ã‚’è¨ˆç®—
    df_train['è£œæ­£é †ä½'] = df_train.groupby(race_id_col)['éå»3èµ°MAXè£œæ­£'].rank(ascending=False, method='min')
else:
    df_train['æŒ‡æ•°é †ä½'] = 10; df_train['è£œæ­£é †ä½'] = 10

# ç‰¹å¾´é‡ãƒªã‚¹ãƒˆ
features = ['æŒ‡æ•°', 'éå»3èµ°MAXè£œæ­£', 'æŒ‡æ•°é †ä½', 'è£œæ­£é †ä½']

# å­¦ç¿’å®Ÿè¡Œ
print("ğŸ”¥ éå»3èµ°è©•ä¾¡ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­...")
X = df_train[features]
y = df_train['target']

model = lgb.LGBMClassifier(random_state=42, n_estimators=100)
calibrated_model = CalibratedClassifierCV(model, method='isotonic', cv=3)
calibrated_model.fit(X, y)
print("âœ… å­¦ç¿’å®Œäº†ï¼")

# ------------------------------------------------
# 2. æœ€æ–°ã‚ªãƒƒã‚ºã§ã®äºˆæƒ³ (å‡ºé¦¬è¡¨ã®å‡¦ç†)
# ------------------------------------------------
print(f"ğŸš€ æœ€æ–°ã®å‡ºé¦¬è¡¨({entry_file})ã§äºˆæƒ³ã—ã¾ã™...")

try:
    df_entry = pd.read_csv(entry_file, encoding='utf-8-sig')
except:
    try:
        df_entry = pd.read_csv(entry_file, encoding='cp932')
    except:
        df_entry = pd.read_csv(entry_file, encoding='shift_jis', errors='replace')

df_entry.columns = df_entry.columns.str.strip()
df_entry = df_entry.loc[:, ~df_entry.columns.duplicated()]
df_pred = df_entry.copy()

# --- â˜…å‡ºé¦¬è¡¨ã‹ã‚‰éå»3èµ°ã®MAXè£œæ­£ã‚’å–å¾— ---
# å‡ºé¦¬è¡¨ã®åˆ—å (è£œ:1, è£œ:2, è£œ:3) ã‚’æ¢ã™
hosei_cols = ['è£œ:1', 'è£œ:2', 'è£œ:3']
target_hosei_cols = []

# å®Ÿéš›ã«å­˜åœ¨ã™ã‚‹åˆ—ã ã‘ä½¿ã† (è£œæ­£ã‚¿ã‚¤ãƒ .1 ãªã©ã®å ´åˆã‚‚å¯¾å¿œ)
for c in hosei_cols:
    if c in df_pred.columns: target_hosei_cols.append(c)
if not target_hosei_cols:
    # åˆ¥åã§æ¢ã™
    for i in range(1, 4):
        c = f'è£œæ­£ã‚¿ã‚¤ãƒ .{i}'
        if c in df_pred.columns: target_hosei_cols.append(c)

print(f"â„¹ï¸ å‚ç…§ã™ã‚‹éå»èµ°ãƒ‡ãƒ¼ã‚¿: {target_hosei_cols}")

# æœ€å¤§å€¤ã‚’è¨ˆç®—
def get_entry_max_hosei(row):
    vals = []
    for c in target_hosei_cols:
        v = force_numeric(row[c])
        if v > 0: vals.append(v)
    return max(vals) if vals else 0

df_pred['éå»3èµ°MAXè£œæ­£'] = df_pred.apply(get_entry_max_hosei, axis=1)

# ãã®ä»–ã®ãƒãƒƒãƒ”ãƒ³ã‚°
if 'ZI' in df_pred.columns: df_pred['æŒ‡æ•°'] = df_pred['ZI'].apply(force_numeric).fillna(0)
else: df_pred['æŒ‡æ•°'] = 0

# å˜å‹ã‚ªãƒƒã‚º
odds_col = 'å˜å‹' if 'å˜å‹' in df_pred.columns else 'å˜å‹ã‚ªãƒƒã‚º'
if odds_col in df_pred.columns:
    df_pred['å˜å‹ã‚ªãƒƒã‚º'] = df_pred[odds_col].apply(force_numeric).fillna(0)
else:
    df_pred['å˜å‹ã‚ªãƒƒã‚º'] = 0

# ãƒ©ãƒ³ã‚¯è¨ˆç®—
race_key = 'ãƒ¬ãƒ¼ã‚¹å' if 'ãƒ¬ãƒ¼ã‚¹å' in df_pred.columns else 'é–‹å‚¬'
if race_key not in df_pred.columns: df_pred['dummy']=1; race_key='dummy'

df_pred['æŒ‡æ•°é †ä½'] = df_pred.groupby(race_key)['æŒ‡æ•°'].rank(ascending=False, method='min')
df_pred['è£œæ­£é †ä½'] = df_pred.groupby(race_key)['éå»3èµ°MAXè£œæ­£'].rank(ascending=False, method='min')

# äºˆæ¸¬
X_pred = df_pred[features]
probs = calibrated_model.predict_proba(X_pred)[:, 1]
df_pred['AIå‹ç‡(%)'] = (probs * 100).round(2)
df_pred['æœŸå¾…å€¤'] = (df_pred['AIå‹ç‡(%)'] / 100) * df_pred['å˜å‹ã‚ªãƒƒã‚º']

# é¦¬å
name_col = [c for c in df_pred.columns if 'é¦¬å' in c]
name_c = name_col[0] if name_col else 'Unknown'

# è¨ºæ–­
def make_comment(row):
    res = []
    if row['æŒ‡æ•°é †ä½'] == 1: res.append("æŒ‡æ•°1ä½")
    if row['è£œæ­£é †ä½'] == 1: res.append("èƒ½åŠ›1ä½")
    elif row['è£œæ­£é †ä½'] <= 3: res.append("èƒ½åŠ›ä¸Šä½")
    if row['æœŸå¾…å€¤'] >= 1.2: res.append("â˜…ç‹™ã„ç›®")
    return ",".join(res) if res else "-"

df_pred['è¨ºæ–­'] = df_pred.apply(make_comment, axis=1)

# --- çµæœå‡ºåŠ› ---
cols_out = ['æ ç•ª', 'é¦¬ç•ª', name_c, 'å˜å‹ã‚ªãƒƒã‚º', 'AIå‹ç‡(%)', 'æœŸå¾…å€¤', 'è¨ºæ–­', 'æŒ‡æ•°', 'éå»3èµ°MAXè£œæ­£']
disp_cols = [c for c in cols_out if c in df_pred.columns]

print("\n=== ğŸ’° æœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚° (å›åç‡é‡è¦–) ===")
print(df_pred.sort_values('æœŸå¾…å€¤', ascending=False)[disp_cols].head(15))

print("\n=== ğŸ… AIå‹ç‡ãƒ©ãƒ³ã‚­ãƒ³ã‚° (çš„ä¸­ç‡é‡è¦–) ===")
print(df_pred.sort_values('AIå‹ç‡(%)', ascending=False)[disp_cols].head(15))